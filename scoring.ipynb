{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/pydantic/_internal/_config.py:321: UserWarning: Valid config keys have changed in V2:\n",
      "* 'underscore_attrs_are_private' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import text2term\n",
    "import re\n",
    "import ast\n",
    "import csv\n",
    "\n",
    "from collections import Counter, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_output = pd.read_csv('outputs/raw_model_outputs.csv')\n",
    "gpt_output = pd.read_csv('outputs/tqvhttfm.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use if predictions and ground truth are not already sets in the CSV\n",
    "gpt_output[\"Predictions\"] = gpt_output[\"Predictions\"].apply(lambda preds: set(map(str.strip, next(csv.reader([preds])))))\n",
    "# gpt_output['Ground Truth'] = gpt_output[\"Ground Truth\"].apply(lambda truth: set(map(str.strip, next(csv.reader([truth])))))\n",
    "\n",
    "## Below is a more robust way to split the strings into sets (I only used them when hard-coding the CSV i.e, IMMPORT.csv)\n",
    "# gpt_output['Predictions'] = gpt_output['Predictions'].apply(lambda preds: set(s.strip('\"') for s in re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', preds)))\n",
    "gpt_output['Ground Truth'] = gpt_output['Ground Truth'].apply(lambda truth: set(s.strip('\"') for s in re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use if predictions and ground truth are already sets in the CSV\n",
    "# gpt_output['Ground Truth'] = gpt_output['Ground Truth'].apply(lambda str: set(ast.literal_eval(str)))\n",
    "# gpt_output['Predictions'] = gpt_output['Predictions'].apply(lambda str: set(ast.literal_eval(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any EDAM not in the list\n",
    "with open('EDAM/edam_topics.txt') as edam_file:\n",
    "    full_edam_topics = edam_file.readlines()\n",
    "\n",
    "full_edam_topics = [topic.strip() for topic in full_edam_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['Hallucinations'] = gpt_output['Predictions'].apply(lambda preds: set([pred.replace('.', '').replace('\\\"', '') for pred in preds if pred.replace('.', '').replace('\\\"', '') not in full_edam_topics]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['Ground Truth'] = gpt_output['Ground Truth'].apply(lambda x: set([term.replace('Zoology', 'Animal study').replace('Drug metabolism', '') for term in x]))\n",
    "\n",
    "# Remove Hallucinated Topics and misplaced punctuation\n",
    "gpt_output['Predictions'] = gpt_output['Predictions'].apply(lambda preds: set([pred.replace('.', '').replace('\\\"', '') for pred in preds if pred.replace('.', '').replace('\\\"', '') in full_edam_topics]))\n",
    "gpt_output['Predictions'] = gpt_output.apply(lambda row: set([topic for topic in row['Predictions'] if topic not in row['Hallucinations']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(row):\n",
    "    set1, set2 = row['Ground Truth'], row['Predictions']\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "     \n",
    "    return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['Jaccard Similarity'] = gpt_output.apply(jaccard_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "gpt-3.5-turbo    Axes(0.125,0.11;0.775x0.77)\n",
       "Name: Jaccard Similarity, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "gpt_output.groupby('Model')['Jaccard Similarity'].plot(kind='hist', alpha=0.8, legend=True, edgecolor='black', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Axes' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_labels):\n\u001b[1;32m      8\u001b[0m     subset \u001b[38;5;241m=\u001b[39m gpt_output[gpt_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m label]\n\u001b[0;32m----> 9\u001b[0m     \u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mhist(subset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaccard Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39mlabel, color\u001b[38;5;241m=\u001b[39mcolors[i])\n\u001b[1;32m     10\u001b[0m     axs[i]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistogram for Model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     axs[i]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaccard Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Axes' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_labels = gpt_output['Model'].unique()\n",
    "\n",
    "fig, axs = plt.subplots(len(unique_labels), 1, figsize=(6, 4 * len(unique_labels)), sharex=True)\n",
    "\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'magenta']\n",
    "# Plot histograms for each label\n",
    "for i, label in enumerate(unique_labels):\n",
    "    subset = gpt_output[gpt_output['Model'] == label]\n",
    "    axs[i].hist(subset['Jaccard Similarity'], bins=10, alpha=0.7, edgecolor='black', label=label, color=colors[i])\n",
    "    axs[i].set_title(f'Histogram for Model {label}')\n",
    "    axs[i].set_xlabel('Jaccard Similarity')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather more model metrics\n",
    "\n",
    "Precision, Recall, Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0.6666666666666666, 0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0, 0, 0, 0, 0.3333333333333333, 0.5, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3333333333333333, 0.3333333333333333, 0.5, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.5, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, 0.6666666666666666, 0.5, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.5, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5, 1.0, 0.5, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.5, 0.3333333333333333, 0.0, 0.0, 0.5, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5, 0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.5, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.5, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.5, 0.0, 0.5, 0.5, 0.3333333333333333, 0.5, 1.0, 0.3333333333333333, 0.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, 1.0, 0.3333333333333333, 0.5, 1.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.0, 0.5, 0.3333333333333333, 0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.0, 0.0, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333, 0.6666666666666666, 1.0, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.0, 0.3333333333333333, 0.0, 0.5, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.5, 0.5, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.5, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, 0.0, 0.6666666666666666, 0.3333333333333333, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.5, 0.3333333333333333, 0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0, 0.6666666666666666, 0.5, 0.5, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.5, 0, 0.3333333333333333, 0.6666666666666666, 0.5, 1.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.3333333333333333, 0.5]\n",
      "Recall: [0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "def calculate_precision_recall_per_row(ground_truth, predictions):\n",
    "    precision_per_row = []\n",
    "    recall_per_row = []\n",
    "\n",
    "    for truth_labels, predicted_labels in zip(ground_truth, predictions):\n",
    "\n",
    "        true_positives = len(truth_labels.intersection(predicted_labels))\n",
    "        false_positives = len(predicted_labels - truth_labels)\n",
    "        false_negatives = len(truth_labels - predicted_labels)\n",
    "\n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
    "\n",
    "        precision_per_row.append(precision)\n",
    "        recall_per_row.append(recall)\n",
    "\n",
    "    return precision_per_row, recall_per_row\n",
    "\n",
    "\n",
    "precision, recall = calculate_precision_recall_per_row(gpt_output['Ground Truth'], gpt_output['Predictions'])\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['Precision'] = precision\n",
    "gpt_output['Recall'] = recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added terms & Subtracted terms\n",
    "\n",
    "Added terms and subtracted terms for each model against gpt3.5 and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Against ground truth\n",
    "def find_added_missing_labels(ground_truth, predictions):\n",
    "    added_labels_per_row = []\n",
    "    missing_labels_per_row = []\n",
    "\n",
    "    for truth_labels, predicted_labels in zip(ground_truth, predictions):\n",
    "\n",
    "        added_labels = predicted_labels - truth_labels\n",
    "        missing_labels = truth_labels - predicted_labels\n",
    "\n",
    "        added_labels_per_row.append(added_labels)\n",
    "        missing_labels_per_row.append(missing_labels)\n",
    "\n",
    "    return added_labels_per_row, missing_labels_per_row\n",
    "\n",
    "added_labels_per_row, missing_labels_per_row = find_added_missing_labels(gpt_output['Ground Truth'], gpt_output['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['Added Labels (Predictions against Ground Truth)'] = added_labels_per_row\n",
    "gpt_output['Missing Labels (Predictions against Ground Truth)'] = missing_labels_per_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the reference model name you want to compare others against\n",
    "reference_model_name = 'gpt-3.5-turbo'\n",
    "\n",
    "added_labels, missing_labels = [], []\n",
    "gpt3_preds = gpt_output[gpt_output['Model'] == reference_model_name]['Predictions']\n",
    "\n",
    "for name, group in gpt_output.groupby('Model'):\n",
    "    if name == reference_model_name:\n",
    "        added_labels.extend(['N/A'] * 25)\n",
    "        missing_labels.extend(['N/A'] * 25)\n",
    "        continue\n",
    "    \n",
    "    added_labels_per_row, missing_labels_per_row = find_added_missing_labels(gpt3_preds, group['Predictions'])\n",
    "    \n",
    "    added_labels.extend(added_labels_per_row)\n",
    "    missing_labels.extend(missing_labels_per_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['Added Labels (Predictions against GPT-3.5)'] = added_labels\n",
    "gpt_output['Missing Labels (Predictions against GPT-3.5)'] = missing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any EDAM not in the list\n",
    "with open('EDAM/edam_topics.txt', 'r') as edam_file:\n",
    "    full_edam_topics = edam_file.readlines()\n",
    "\n",
    "full_edam_topics = [topic.strip().replace('\\\"', '') for topic in full_edam_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather average values \n",
    "\n",
    "def get_average_metrics(dataset, average_metrics: dict, column_name):\n",
    "    for name, group in dataset.groupby('Model'):\n",
    "        average_metrics[name] = group[column_name].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_jaccard = dict()\n",
    "average_precision = dict()\n",
    "average_recall = dict()\n",
    "\n",
    "get_average_metrics(gpt_output, average_jaccard, 'Jaccard Similarity')\n",
    "get_average_metrics(gpt_output, average_precision, 'Precision')\n",
    "get_average_metrics(gpt_output, average_recall, 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ft:gpt-3.5-turbo-0613:personal::8SAHvdnS': 0.14539003846245735, 'ft:gpt-3.5-turbo-0613:personal::8SD8i1on': 0.17692454913507544, 'ft:gpt-3.5-turbo-1106:personal::8SDAGTmv': 0.15975781150394153, 'gpt-3.5-turbo': 0.14825713983299124, 'gpt-4': 0.047351791998850826, 'mixtral-8x7b-model': 0.08302678432678434} \n",
      "\n",
      "{'ft:gpt-3.5-turbo-0613:personal::8SAHvdnS': 0.22613553113553114, 'ft:gpt-3.5-turbo-0613:personal::8SD8i1on': 0.2645934065934066, 'ft:gpt-3.5-turbo-1106:personal::8SDAGTmv': 0.23906349206349206, 'gpt-3.5-turbo': 0.2607936507936508, 'gpt-4': 0.09438095238095238, 'mixtral-8x7b-model': 0.13594042799305955} \n",
      "\n",
      "{'ft:gpt-3.5-turbo-0613:personal::8SAHvdnS': 0.2918210678210678, 'ft:gpt-3.5-turbo-0613:personal::8SD8i1on': 0.3542453102453102, 'ft:gpt-3.5-turbo-1106:personal::8SDAGTmv': 0.32689466089466085, 'gpt-3.5-turbo': 0.243008658008658, 'gpt-4': 0.08246176046176046, 'mixtral-8x7b-model': 0.16765512265512264} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(average_jaccard, '\\n')\n",
    "print(average_precision, '\\n')\n",
    "print(average_recall, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output.to_csv('outputs/filtered_outputs_w_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Scoring Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate J-similarity, precision, recall and then remove the terms in common\n",
    "\n",
    "2. Check if a prediction term is within the same tree as a ground truth term\n",
    "\n",
    "3. If two terms are within the same tree:\n",
    "\n",
    "- Treat the two terms as a match\n",
    "- Determine which term is closer to the root ([http://edamontology.org/topic\\_0003](http://edamontology.org/topic_0003))\n",
    "  - Calculate a weight to apply depending on how close the closest term is to the root (Weight 1)\n",
    "    - If closest term is one step away from root it should have a lower score than a closest term that is 2 steps away. This is to lower the weight of excessively generic terms (use: 1-(1/(# of steps to closest term))\n",
    "  - Calculate a weight to apply depending on the number of steps between the two 'matching' terms (Weight 2)\n",
    "    - If the closest term to root is the ground truth term, use: (1/(# of steps between the terms))\n",
    "    - If the closest term to root is the prediction term, use: -(1/(# of steps between the terms)): It is negative only to ensure we will later be able to inspect the directionality\n",
    "- The overall weight should be a combination of the two, for example:\n",
    "- Overall weight = Weight 1 + ABS(Weight 2)\n",
    "- Weighted similarity: Add the overall weight for all matches, then add the j-sim (since we previously removed exact matches)\n",
    "\n",
    "**Adjusting for prediction number biases:**\n",
    "\n",
    "- The weighted similarity will be advantageous to ChatGPT 4 due to its tendency to dump every relevant term\n",
    "- To account for that, we can penalize it for making excessive guesses by multiplying the weighted similarity against the ratio of (# of gold standard terms)/(# of predicted terms).\n",
    "\n",
    "**Evaluating whether the prediction has a tendency to be more specific or less specific than the gold standard**\n",
    "\n",
    "- Broadness evaluation: (# of positive Weight 2 values)/(# of negative Weight 2 values)\n",
    "- If broadness evaluation is \\>1, LLM model predictions are more specific than Ground truth/gold standard terms\n",
    "  - If broadness evaluation is \\<1, LLM model predictions are less specific than ground truth/gold standard terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edam_data = pd.read_csv(\"EDAM/EDAM.csv\")\n",
    "edam_data = edam_data[edam_data['Class ID'].str.startswith(\"http://edamontology.org/topic_\")].sort_values(by='Preferred Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class ID</th>\n",
       "      <th>Preferred Label</th>\n",
       "      <th>Parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>http://edamontology.org/topic_3521</td>\n",
       "      <td>2D PAGE experiment</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#DeprecatedClass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>http://edamontology.org/topic_0174</td>\n",
       "      <td>Ab initio structure prediction</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#DeprecatedClass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>http://edamontology.org/topic_0083</td>\n",
       "      <td>Alignment</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#DeprecatedClass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>http://edamontology.org/topic_0786</td>\n",
       "      <td>Arabidopsis</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#DeprecatedClass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>http://edamontology.org/topic_3075</td>\n",
       "      <td>Biological system modelling</td>\n",
       "      <td>http://www.w3.org/2002/07/owl#DeprecatedClass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Class ID                 Preferred Label  \\\n",
       "2996  http://edamontology.org/topic_3521              2D PAGE experiment   \n",
       "3002  http://edamontology.org/topic_0174  Ab initio structure prediction   \n",
       "3329  http://edamontology.org/topic_0083                       Alignment   \n",
       "1690  http://edamontology.org/topic_0786                     Arabidopsis   \n",
       "2435  http://edamontology.org/topic_3075     Biological system modelling   \n",
       "\n",
       "                                            Parents  \n",
       "2996  http://www.w3.org/2002/07/owl#DeprecatedClass  \n",
       "3002  http://www.w3.org/2002/07/owl#DeprecatedClass  \n",
       "3329  http://www.w3.org/2002/07/owl#DeprecatedClass  \n",
       "1690  http://www.w3.org/2002/07/owl#DeprecatedClass  \n",
       "2435  http://www.w3.org/2002/07/owl#DeprecatedClass  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edam_data[~edam_data['Parents'].str.contains(\"http://edamontology.org/topic_\")].head()[['Class ID', 'Preferred Label', 'Parents']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam_data = edam_data[edam_data['Parents'].str.contains(\"http://edamontology.org/topic_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam_data['Parents #'] = edam_data['Parents'].str.extractall(r'topic_(\\d+)').groupby(level=0).agg(lambda parents: parents.tolist())\n",
    "edam_data['Topic #'] = edam_data['Class ID'].apply(lambda url: url.split('topic_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "plabel_topic_dict = dict(zip(edam_data['Preferred Label'], edam_data['Topic #']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "topic_dict = defaultdict(list)\n",
    "\n",
    "for index, row in edam_data.iterrows():\n",
    "    topic = row['Topic #']\n",
    "    parents = row['Parents #']\n",
    "    \n",
    "    topic_dict[topic].extend(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def shortest_distance(topic_dict, topic, verbose=False):\n",
    "    \n",
    "    queue = [(topic, 0, [topic])]\n",
    "    visited = set()\n",
    "    \n",
    "    while queue:\n",
    "        current_topic, distance, path = queue.pop(0)\n",
    "        \n",
    "        if current_topic == '0003':\n",
    "            if verbose:\n",
    "                print('Path to root: ', path)\n",
    "            return distance\n",
    "        \n",
    "        visited.add(current_topic)\n",
    "        \n",
    "        if current_topic in topic_dict:\n",
    "            parents = topic_dict[current_topic]\n",
    "            \n",
    "            for parent in parents:\n",
    "                if parent not in visited:\n",
    "                    queue.append((parent, distance + 1, path + [parent]))\n",
    "    \n",
    "    return -1  # If the root topic is not found\n",
    "\n",
    "dist = shortest_distance(topic_dict, '4030')\n",
    "\n",
    "print(dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4019: ['3070', '3344', '3307', '0610', '3303', '3391', '3810', '3292', '3360', '3306', '3297', '2229', '3369', '3064', '3299', '3573', '3053', '2815', '3387', '3301', '0621', '3047', '0780', '1317', '3895', '2259', '0781', '3500', '4030', '3398', '3368', '3912', '3576', '3939', '4030', '3895', '3065', '3945', '3298', '0084', '0637', '3944', '3293', '3295', '3912', '0625', '3574', '3930', '3321', '3056', '3173', '4037', '3974', '3945', '3298', '3055', '3959', '0623', '0203', '0114', '0199', '2830', '0204', '3941', '3320', '0749', '3308', '3941', '4027', '0659', '3512', '0798', '2533', '2885', '3175', '3958', '4013', '3697', '4038', '0611', '0593', '3448', '0122', '2828', '4017', '3067', '0804', '3386', '3376', '3304', '3390', '3302', '0202', '3395', '3277', '3930', '3948', '2830', '3679', '3374', '3373', '3336', '3375', '3379', '3393', '3394', '3377', '3966', '3343', '0209', '3378', '2840', '0208', '3337', '3340', '3341', '3339', '3338', '3892', '1775', '3321', '0602', '0077', '0084', '0078', '0080', '0160', '0081', '0176', '0085', '3959', '0623', '0203', '0114', '0199', '2830', '0204', '3941', '3320', '0749', '3308', '3941', '4027', '0659', '3512', '0798', '2533', '2885', '3175', '3958', '0128', '0654', '3511', '0097', '0099', '3125', '2533', '3176', '2885', '3127', '3175', '0749', '3958', '3125', '0749', '0659', '3512', '3320', '3944', '3293', '0821', '0623', '0820', '0108', '0128', '0123', '3510', '2814', '0749', '2830', '0601', '0140', '3120', '3534', '3538', '0130', '0736', '3542', '0166', '3944', '0102', '4038', '3293', '0194', '0632', '0196', '0157', '3511', '3510', '3125', '0749', '3534', '0152', '0153', '0097', '2814', '0154', '0082', '3538', '0130', '0736', '3542', '0166', '0176', '2275', '3050', '4020', '3174', '3697', '4038', '3400', '3402', '3335', '3423', '3403', '3405', '3404', '3406', '3407', '3409', '3410', '3399', '3411', '3408', '3412', '3415', '3416', '3334', '2640', '3417', '3418', '3401', '0634', '3577', '3300', '3419', '3305', '3420', '3322', '3421', '3396', '2840', '3342', '3414', '3575', '3422', '3397', '3324', '3325', '4013', '4016', '4014', '3388', '3955', '0622', '3967', '3172', '3945', '4021', '3298', '0121', '0797', '3173', '0085', '0199', '3174', '3943', '0208', '0194', '3796', '3922', '0122', '3308', '2533', '2885', '3175', '3958', '3941', '4027']\n",
      "3314: ['3370', '3292', '4020', '3332', '3336', '3371', '4030', '3343', '0209', '3369', '0209']\n",
      "3316: ['3332', '3473', '0092', '3474', '0218', '3372']\n",
      "3071: ['3077', '3365', '3571', '3345', '3366', '3572', '4011', '3263', '0219', '4012', '0769']\n",
      "3855: ['4020', '0610', '3050', '4020', '3174', '3697', '4038']\n",
      "3678: ['3679', '3517', '3379']\n",
      "0605: ['0091', '2258', '3489', '3948', '0607', '3063', '0089', '3931']\n",
      "3361: ['3940', '3934', '3516', '3382', '3656', '3518', '3519', '3957', '3520', '3523', '3168', '3524', '3383', '3954', '4016', '4014', '0611', '3385', '3444', '3384', '0593', '3448', '3452', '2828', '4017', '3179', '3169', '3674', '3794', '3169', '3676', '3923', '3837', '3170', '4028', '3673']\n",
      "3068: ['0218']\n",
      "3315: ['3569', '3570', '2269']\n",
      "4010: ['4012']\n",
      "3318: ['4029', '3306', '4020', '4030']\n"
     ]
    }
   ],
   "source": [
    "parent_topic = '0003'\n",
    "subtree_dict = {}\n",
    "\n",
    "for topic, parents in topic_dict.items():\n",
    "    if parent_topic in parents:\n",
    "        subtree_dict[topic] = []\n",
    "\n",
    "def get_children_topics(parent_id):\n",
    "    # children_ids = edam_data[edam_data['Parents'].str.contains(parent_id)]['Class ID'].apply(lambda url: url.split('topic_')[1]).to_list()\n",
    "    children_ids = edam_data[edam_data['Parents #'].apply(\\\n",
    "        lambda parent_ids: parent_id in parent_ids)]['Topic #'].to_list()\n",
    "    \n",
    "    if not len(children_ids):\n",
    "        return []\n",
    "    \n",
    "    # print(parent_id, children_ids)\n",
    "    \n",
    "    grandchildren = []\n",
    "    for child_id in children_ids:\n",
    "        grandchildren.append(get_children_topics(child_id))\n",
    "    \n",
    "    children_ids.append(grandchildren)\n",
    "    return children_ids\n",
    "\n",
    "for parent_topic in subtree_dict.keys():\n",
    "    subtree_dict[parent_topic] = get_children_topics(parent_topic)\n",
    "# We technically also have the topics which we removed from the EDAM list (laboratory techniques, etc.) but they are inconsequential here.\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    flattened = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "\n",
    "# Flatten each value in the dictionary\n",
    "subtree_dict = {key: flatten_list(value) for key, value in subtree_dict.items()}\n",
    "\n",
    "# Print the flattened dictionary\n",
    "print()\n",
    "for key, value in subtree_dict.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4029': ['3318'],\n",
       " '3810': ['4019'],\n",
       " '3400': ['4019'],\n",
       " '3402': ['4019'],\n",
       " '3370': ['3314'],\n",
       " '3067': ['4019'],\n",
       " '3679': ['4019', '3678'],\n",
       " '4013': ['4019'],\n",
       " '3569': ['3315'],\n",
       " '3337': ['4019'],\n",
       " '3292': ['4019', '3314'],\n",
       " '3050': ['4019', '3855'],\n",
       " '3398': ['4019'],\n",
       " '3383': ['3361'],\n",
       " '0091': ['0605'],\n",
       " '3070': ['4019'],\n",
       " '3360': ['4019'],\n",
       " '3368': ['4019'],\n",
       " '3344': ['4019'],\n",
       " '3892': ['4019'],\n",
       " '3306': ['4019', '3318'],\n",
       " '4019': [],\n",
       " '3297': ['4019'],\n",
       " '3374': ['4019'],\n",
       " '0152': ['4019'],\n",
       " '4020': ['4019', '3314', '3855', '3318'],\n",
       " '3335': ['4019'],\n",
       " '2229': ['4019'],\n",
       " '3340': ['4019'],\n",
       " '3179': ['3361'],\n",
       " '3169': ['3361'],\n",
       " '3369': ['4019', '3314'],\n",
       " '2258': ['0605'],\n",
       " '3314': [],\n",
       " '3931': ['0605'],\n",
       " '3940': ['3361'],\n",
       " '3944': ['4019'],\n",
       " '3341': ['4019'],\n",
       " '0797': ['4019'],\n",
       " '3423': ['4019'],\n",
       " '3343': ['4019', '3314'],\n",
       " '3307': ['4019'],\n",
       " '3332': ['3314', '3316'],\n",
       " '3316': [],\n",
       " '3958': ['4019'],\n",
       " '3403': ['4019'],\n",
       " '4017': ['4019', '3361'],\n",
       " '3959': ['4019'],\n",
       " '3934': ['3361'],\n",
       " '0654': ['4019'],\n",
       " '3125': ['4019'],\n",
       " '2533': ['4019'],\n",
       " '3176': ['4019'],\n",
       " '2885': ['4019'],\n",
       " '3127': ['4019'],\n",
       " '3077': ['3071'],\n",
       " '3365': ['3071'],\n",
       " '3571': ['3071'],\n",
       " '3345': ['3071'],\n",
       " '3366': ['3071'],\n",
       " '3071': [],\n",
       " '3473': ['3316'],\n",
       " '3572': ['3071'],\n",
       " '4011': ['3071'],\n",
       " '3263': ['3071'],\n",
       " '0219': ['3071'],\n",
       " '0092': ['3316'],\n",
       " '3489': ['0605'],\n",
       " '3405': ['4019'],\n",
       " '3404': ['4019'],\n",
       " '3064': ['4019'],\n",
       " '3373': ['4019'],\n",
       " '3336': ['4019', '3314'],\n",
       " '3375': ['4019'],\n",
       " '3406': ['4019'],\n",
       " '3954': ['3361'],\n",
       " '0610': ['4019', '3855'],\n",
       " '4016': ['4019', '3361'],\n",
       " '4014': ['4019', '3361'],\n",
       " '0611': ['4019', '3361'],\n",
       " '3065': ['4019'],\n",
       " '3407': ['4019'],\n",
       " '3855': [],\n",
       " '0821': ['4019'],\n",
       " '3295': ['4019'],\n",
       " '3173': ['4019'],\n",
       " '3974': ['4019'],\n",
       " '3299': ['4019'],\n",
       " '3676': ['3361'],\n",
       " '3678': [],\n",
       " '4012': ['3071', '4010'],\n",
       " '3955': ['4019'],\n",
       " '3573': ['4019'],\n",
       " '1775': ['4019'],\n",
       " '0085': ['4019'],\n",
       " '0659': ['4019'],\n",
       " '3517': ['3678'],\n",
       " '3409': ['4019'],\n",
       " '3410': ['4019'],\n",
       " '0623': ['4019'],\n",
       " '0203': ['4019'],\n",
       " '0204': ['4019'],\n",
       " '0114': ['4019'],\n",
       " '3512': ['4019'],\n",
       " '3912': ['4019'],\n",
       " '0199': ['4019'],\n",
       " '3053': ['4019'],\n",
       " '3923': ['3361'],\n",
       " '4037': ['4019'],\n",
       " '0622': ['4019'],\n",
       " '0625': ['4019'],\n",
       " '3516': ['3361'],\n",
       " '3399': ['4019'],\n",
       " '3411': ['4019'],\n",
       " '3408': ['4019'],\n",
       " '3412': ['4019'],\n",
       " '2815': ['4019'],\n",
       " '3574': ['4019'],\n",
       " '3382': ['3361'],\n",
       " '3930': ['4019'],\n",
       " '3948': ['4019', '0605'],\n",
       " '0804': ['4019'],\n",
       " '3967': ['4019'],\n",
       " '3656': ['3361'],\n",
       " '2830': ['4019'],\n",
       " '3324': ['4019'],\n",
       " '0605': [],\n",
       " '3386': ['4019'],\n",
       " '0607': ['0605'],\n",
       " '3361': [],\n",
       " '3385': ['3361'],\n",
       " '0153': ['4019'],\n",
       " '3068': [],\n",
       " '3444': ['3361'],\n",
       " '3474': ['3316'],\n",
       " '0102': ['4019'],\n",
       " '3387': ['4019'],\n",
       " '3315': [],\n",
       " '3576': ['4019'],\n",
       " '3384': ['3361'],\n",
       " '3063': ['0605'],\n",
       " '3415': ['4019'],\n",
       " '0209': ['4019', '3314'],\n",
       " '3303': ['4019'],\n",
       " '3376': ['4019'],\n",
       " '0820': ['4019'],\n",
       " '4038': ['4019', '3855'],\n",
       " '3939': ['4019'],\n",
       " '3172': ['4019'],\n",
       " '3837': ['3361'],\n",
       " '3174': ['4019', '3855'],\n",
       " '3941': ['4019'],\n",
       " '3674': ['3361'],\n",
       " '3518': ['3361'],\n",
       " '3339': ['4019'],\n",
       " '3697': ['4019', '3855'],\n",
       " '3301': ['4019'],\n",
       " '4030': ['4019', '3314', '3318'],\n",
       " '0798': ['4019'],\n",
       " '0621': ['4019'],\n",
       " '3047': ['4019'],\n",
       " '0176': ['4019'],\n",
       " '3945': ['4019'],\n",
       " '3321': ['4019'],\n",
       " '0602': ['4019'],\n",
       " '3388': ['4019'],\n",
       " '2275': ['4019'],\n",
       " '3338': ['4019'],\n",
       " '4021': ['4019'],\n",
       " '3416': ['4019'],\n",
       " '0593': ['4019', '3361'],\n",
       " '0218': ['3316', '3068'],\n",
       " '3304': ['4019'],\n",
       " '3334': ['4019'],\n",
       " '3448': ['4019', '3361'],\n",
       " '3511': ['4019'],\n",
       " '0097': ['4019'],\n",
       " '0077': ['4019'],\n",
       " '3390': ['4019'],\n",
       " '3391': ['4019'],\n",
       " '2640': ['4019'],\n",
       " '0089': ['0605'],\n",
       " '4010': [],\n",
       " '3417': ['4019'],\n",
       " '3519': ['3361'],\n",
       " '3418': ['4019'],\n",
       " '3401': ['4019'],\n",
       " '3943': ['4019'],\n",
       " '3302': ['4019'],\n",
       " '0634': ['4019'],\n",
       " '3577': ['4019'],\n",
       " '0208': ['4019'],\n",
       " '0202': ['4019'],\n",
       " '3378': ['4019'],\n",
       " '3298': ['4019'],\n",
       " '3293': ['4019'],\n",
       " '0194': ['4019'],\n",
       " '0084': ['4019'],\n",
       " '3318': [],\n",
       " '3300': ['4019'],\n",
       " '0780': ['4019'],\n",
       " '3056': ['4019'],\n",
       " '3796': ['4019'],\n",
       " '3379': ['4019', '3678'],\n",
       " '0632': ['4019'],\n",
       " '3534': ['4019'],\n",
       " '3538': ['4019'],\n",
       " '0108': ['4019'],\n",
       " '0130': ['4019'],\n",
       " '0736': ['4019'],\n",
       " '3957': ['3361'],\n",
       " '0128': ['4019'],\n",
       " '0601': ['4019'],\n",
       " '0123': ['4019'],\n",
       " '3542': ['4019'],\n",
       " '3510': ['4019'],\n",
       " '0166': ['4019'],\n",
       " '2814': ['4019'],\n",
       " '0140': ['4019'],\n",
       " '3120': ['4019'],\n",
       " '0078': ['4019'],\n",
       " '3922': ['4019'],\n",
       " '0121': ['4019'],\n",
       " '3520': ['3361'],\n",
       " '3419': ['4019'],\n",
       " '3305': ['4019'],\n",
       " '3570': ['3315'],\n",
       " '3393': ['4019'],\n",
       " '3055': ['4019'],\n",
       " '0099': ['4019'],\n",
       " '3794': ['3361'],\n",
       " '3320': ['4019'],\n",
       " '3170': ['3361'],\n",
       " '3523': ['3361'],\n",
       " '3325': ['4019'],\n",
       " '3395': ['4019'],\n",
       " '3394': ['4019'],\n",
       " '3420': ['4019'],\n",
       " '3322': ['4019'],\n",
       " '4027': ['4019'],\n",
       " '3377': ['4019'],\n",
       " '3277': ['4019'],\n",
       " '0080': ['4019'],\n",
       " '0196': ['4019'],\n",
       " '0157': ['4019'],\n",
       " '0160': ['4019'],\n",
       " '3168': ['3361'],\n",
       " '3524': ['3361'],\n",
       " '4028': ['3361'],\n",
       " '0154': ['4019'],\n",
       " '3372': ['3316'],\n",
       " '2269': ['3315'],\n",
       " '1317': ['4019'],\n",
       " '0122': ['4019'],\n",
       " '3175': ['4019'],\n",
       " '0081': ['4019'],\n",
       " '0082': ['4019'],\n",
       " '3421': ['4019'],\n",
       " '3895': ['4019'],\n",
       " '3371': ['3314'],\n",
       " '2259': ['4019'],\n",
       " '3396': ['4019'],\n",
       " '0637': ['4019'],\n",
       " '3452': ['3361'],\n",
       " '2840': ['4019'],\n",
       " '0749': ['4019'],\n",
       " '3308': ['4019'],\n",
       " '3342': ['4019'],\n",
       " '3414': ['4019'],\n",
       " '3575': ['4019'],\n",
       " '3422': ['4019'],\n",
       " '3966': ['4019'],\n",
       " '3397': ['4019'],\n",
       " '0781': ['4019'],\n",
       " '3673': ['3361'],\n",
       " '0769': ['3071'],\n",
       " '2828': ['4019', '3361'],\n",
       " '3500': ['4019']}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_subtree_dict = {}\n",
    "\n",
    "for index, row in edam_data.iterrows():\n",
    "    topic = row['Topic #']\n",
    "    subtrees = []\n",
    "    \n",
    "    for subtree, topics in subtree_dict.items():\n",
    "        if topic in topics:\n",
    "            subtrees.append(subtree)\n",
    "    \n",
    "    topic_subtree_dict[topic] = subtrees\n",
    "\n",
    "topic_subtree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Hallucinations</th>\n",
       "      <th>Jaccard Similarity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIGET: A web portal for study of vaccine-induc...</td>\n",
       "      <td>Host responses to vaccines are complex but imp...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{Bioinformatics, Immunology, Data integration ...</td>\n",
       "      <td>{Infectious disease, Immunology, Allergy, clin...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset from T cell responses to H1N1v and a l...</td>\n",
       "      <td>No description</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{Vaccinology, Infectious disease, Immunology}</td>\n",
       "      <td>{Infectious disease, Immunology, Allergy, clin...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset from T cell responses to H1N1v and a l...</td>\n",
       "      <td>No description</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{Vaccinology, Infectious disease, Immunology}</td>\n",
       "      <td>{Infectious disease, Immunology, Allergy, clin...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset from Defective signaling in aging, inf...</td>\n",
       "      <td>No description</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{Vaccinology, Infectious disease, Immunology}</td>\n",
       "      <td>{Infectious disease, Immunology, Allergy, clin...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Modeling Viral Immunity and Antagonism in Dend...</td>\n",
       "      <td>A suite of ex vivo perturbations are applied t...</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>{Immunology, Computational biology, Infectious...</td>\n",
       "      <td>{Infectious disease, Immunology, Allergy, clin...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0  VIGET: A web portal for study of vaccine-induc...   \n",
       "1  Dataset from T cell responses to H1N1v and a l...   \n",
       "2  Dataset from T cell responses to H1N1v and a l...   \n",
       "3  Dataset from Defective signaling in aging, inf...   \n",
       "4  Modeling Viral Immunity and Antagonism in Dend...   \n",
       "\n",
       "                                         Description          Model  \\\n",
       "0  Host responses to vaccines are complex but imp...  gpt-3.5-turbo   \n",
       "1                                     No description  gpt-3.5-turbo   \n",
       "2                                     No description  gpt-3.5-turbo   \n",
       "3                                     No description  gpt-3.5-turbo   \n",
       "4  A suite of ex vivo perturbations are applied t...  gpt-3.5-turbo   \n",
       "\n",
       "                                         Predictions  \\\n",
       "0  {Bioinformatics, Immunology, Data integration ...   \n",
       "1      {Vaccinology, Infectious disease, Immunology}   \n",
       "2      {Vaccinology, Infectious disease, Immunology}   \n",
       "3      {Vaccinology, Infectious disease, Immunology}   \n",
       "4  {Immunology, Computational biology, Infectious...   \n",
       "\n",
       "                                        Ground Truth Hallucinations  \\\n",
       "0  {Infectious disease, Immunology, Allergy, clin...             {}   \n",
       "1  {Infectious disease, Immunology, Allergy, clin...             {}   \n",
       "2  {Infectious disease, Immunology, Allergy, clin...             {}   \n",
       "3  {Infectious disease, Immunology, Allergy, clin...             {}   \n",
       "4  {Infectious disease, Immunology, Allergy, clin...             {}   \n",
       "\n",
       "   Jaccard Similarity  Precision    Recall  \n",
       "0                 0.2   0.333333  0.333333  \n",
       "1                 0.5   0.666667  0.666667  \n",
       "2                 0.5   0.666667  0.666667  \n",
       "3                 0.5   0.666667  0.666667  \n",
       "4                 0.5   0.666667  0.666667  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = gpt_output\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = data['Ground Truth']\n",
    "predictions = data['Predictions']\n",
    "\n",
    "exclusive_ground_truths = []\n",
    "exclusive_predictions = []\n",
    "\n",
    "for ground_truth, prediction in zip(ground_truths, predictions):\n",
    "    exclusive_ground_truths.append(set([label for label in ground_truth if label not in prediction]))\n",
    "    exclusive_predictions.append(set([label for label in prediction if label not in ground_truth]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Exclusive Ground Truth'] = exclusive_ground_truths\n",
    "data['Exclusive Predictions'] = exclusive_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'4029': ['4029', '3318', '0003'],\n",
       "             '3810': ['3810', '3070', '4019', '0003'],\n",
       "             '3400': ['3400', '3303', '4019', '0003'],\n",
       "             '3402': ['3402', '3303', '4019', '0003'],\n",
       "             '3370': ['3370', '3314', '0003'],\n",
       "             '3067': ['3067', '3344', '4019', '0003'],\n",
       "             '3679': ['3679', '3678', '0003'],\n",
       "             '4013': ['4013', '3301', '3070', '4019', '0003'],\n",
       "             '3569': ['3569', '3315', '0003'],\n",
       "             '3337': ['3337', '3277', '3344', '4019', '0003'],\n",
       "             '3292': ['3292', '3314', '0003'],\n",
       "             '3050': ['3050', '0610', '4019', '0003'],\n",
       "             '3398': ['3398', '3297', '3070', '4019', '0003'],\n",
       "             '3383': ['3383', '3382', '3361', '0003'],\n",
       "             '0091': ['0091', '0605', '0003'],\n",
       "             '3070': ['3070', '4019', '0003'],\n",
       "             '3360': ['3360', '3070', '4019', '0003'],\n",
       "             '3368': ['3368', '3297', '3070', '4019', '0003'],\n",
       "             '3344': ['3344', '4019', '0003'],\n",
       "             '3892': ['3892', '3307', '4019', '0003'],\n",
       "             '3306': ['3306', '3318', '0003'],\n",
       "             '4019': ['4019', '0003'],\n",
       "             '3297': ['3297', '3070', '4019', '0003'],\n",
       "             '3374': ['3374', '3376', '3344', '4019', '0003'],\n",
       "             '0152': ['0152', '0081', '3307', '4019', '0003'],\n",
       "             '4020': ['4020', '3855', '0003'],\n",
       "             '3335': ['3335', '3303', '4019', '0003'],\n",
       "             '2229': ['2229', '3070', '4019', '0003'],\n",
       "             '3340': ['3340', '3277', '3344', '4019', '0003'],\n",
       "             '3179': ['3179', '3656', '3361', '0003'],\n",
       "             '3169': ['3169', '3168', '3361', '0003'],\n",
       "             '3369': ['3369', '3371', '3314', '0003'],\n",
       "             '2258': ['2258', '0605', '0003'],\n",
       "             '3314': ['3314', '0003'],\n",
       "             '3931': ['3931', '2258', '0605', '0003'],\n",
       "             '3940': ['3940', '3361', '0003'],\n",
       "             '3944': ['3944', '0084', '3307', '4019', '0003'],\n",
       "             '3341': ['3341', '3277', '3344', '4019', '0003'],\n",
       "             '0797': ['0797', '0622', '3391', '4019', '0003'],\n",
       "             '3423': ['3423', '3303', '4019', '0003'],\n",
       "             '3343': ['3343', '3336', '3314', '0003'],\n",
       "             '3307': ['3307', '4019', '0003'],\n",
       "             '3332': ['3332', '3316', '0003'],\n",
       "             '3316': ['3316', '0003'],\n",
       "             '3958': ['3958', '3175', '0654', '0077', '3307', '4019', '0003'],\n",
       "             '3403': ['3403', '3303', '4019', '0003'],\n",
       "             '4017': ['4017', '0611', '3382', '3361', '0003'],\n",
       "             '3959': ['3959', '3321', '3307', '4019', '0003'],\n",
       "             '3934': ['3934', '3361', '0003'],\n",
       "             '0654': ['0654', '0077', '3307', '4019', '0003'],\n",
       "             '3125': ['3125', '3511', '0160', '3307', '4019', '0003'],\n",
       "             '2533': ['2533', '0654', '0077', '3307', '4019', '0003'],\n",
       "             '3176': ['3176', '0654', '0077', '3307', '4019', '0003'],\n",
       "             '2885': ['2885', '0654', '0077', '3307', '4019', '0003'],\n",
       "             '3127': ['3127', '0654', '0077', '3307', '4019', '0003'],\n",
       "             '3077': ['3077', '3071', '0003'],\n",
       "             '3365': ['3365', '3071', '0003'],\n",
       "             '3571': ['3571', '3071', '0003'],\n",
       "             '3345': ['3345', '3071', '0003'],\n",
       "             '3366': ['3366', '3071', '0003'],\n",
       "             '3071': ['3071', '0003'],\n",
       "             '3473': ['3473', '3316', '0003'],\n",
       "             '3572': ['3572', '3071', '0003'],\n",
       "             '4011': ['4011', '3071', '0003'],\n",
       "             '3263': ['3263', '3071', '0003'],\n",
       "             '0219': ['0219', '3071', '0003'],\n",
       "             '0092': ['0092', '3316', '0003'],\n",
       "             '3489': ['3489', '0605', '0003'],\n",
       "             '3405': ['3405', '3303', '4019', '0003'],\n",
       "             '3404': ['3404', '3303', '4019', '0003'],\n",
       "             '3064': ['3064', '3070', '4019', '0003'],\n",
       "             '3373': ['3373', '3376', '3344', '4019', '0003'],\n",
       "             '3336': ['3336', '3314', '0003'],\n",
       "             '3375': ['3375', '3376', '3344', '4019', '0003'],\n",
       "             '3406': ['3406', '3303', '4019', '0003'],\n",
       "             '3954': ['3954', '3382', '3361', '0003'],\n",
       "             '0610': ['0610', '4019', '0003'],\n",
       "             '4016': ['4016', '3382', '3361', '0003'],\n",
       "             '4014': ['4014', '3382', '3361', '0003'],\n",
       "             '0611': ['0611', '3382', '3361', '0003'],\n",
       "             '3065': ['3065', '3064', '3070', '4019', '0003'],\n",
       "             '3407': ['3407', '3303', '4019', '0003'],\n",
       "             '3855': ['3855', '0003'],\n",
       "             '0821': ['0821', '0078', '3307', '4019', '0003'],\n",
       "             '3295': ['3295', '3053', '3070', '4019', '0003'],\n",
       "             '3173': ['3173', '0622', '3391', '4019', '0003'],\n",
       "             '3974': ['3974', '0625', '3053', '3070', '4019', '0003'],\n",
       "             '3299': ['3299', '3070', '4019', '0003'],\n",
       "             '3676': ['3676', '3168', '3361', '0003'],\n",
       "             '3678': ['3678', '0003'],\n",
       "             '4012': ['4012', '3071', '0003'],\n",
       "             '3955': ['3955', '3391', '4019', '0003'],\n",
       "             '3573': ['3573', '3070', '4019', '0003'],\n",
       "             '1775': ['1775', '3307', '4019', '0003'],\n",
       "             '0085': ['0085', '0622', '3391', '4019', '0003'],\n",
       "             '0659': ['0659', '0114', '3321', '3307', '4019', '0003'],\n",
       "             '3517': ['3517', '3678', '0003'],\n",
       "             '3409': ['3409', '3303', '4019', '0003'],\n",
       "             '3410': ['3410', '3303', '4019', '0003'],\n",
       "             '0623': ['0623', '3321', '3307', '4019', '0003'],\n",
       "             '0203': ['0203', '3321', '3307', '4019', '0003'],\n",
       "             '0204': ['0204', '0203', '3321', '3307', '4019', '0003'],\n",
       "             '0114': ['0114', '3321', '3307', '4019', '0003'],\n",
       "             '3512': ['3512', '0114', '3321', '3307', '4019', '0003'],\n",
       "             '3912': ['3912', '3053', '3070', '4019', '0003'],\n",
       "             '0199': ['0199', '0622', '3391', '4019', '0003'],\n",
       "             '3053': ['3053', '3070', '4019', '0003'],\n",
       "             '3923': ['3923', '3168', '3361', '0003'],\n",
       "             '4037': ['4037', '3295', '3053', '3070', '4019', '0003'],\n",
       "             '0622': ['0622', '3391', '4019', '0003'],\n",
       "             '0625': ['0625', '3053', '3070', '4019', '0003'],\n",
       "             '3516': ['3516', '3361', '0003'],\n",
       "             '3399': ['3399', '3303', '4019', '0003'],\n",
       "             '3411': ['3411', '3303', '4019', '0003'],\n",
       "             '3408': ['3408', '3303', '4019', '0003'],\n",
       "             '3412': ['3412', '3303', '4019', '0003'],\n",
       "             '2815': ['2815', '3070', '4019', '0003'],\n",
       "             '3574': ['3574', '3053', '3070', '4019', '0003'],\n",
       "             '3382': ['3382', '3361', '0003'],\n",
       "             '3930': ['3930', '3053', '3070', '4019', '0003'],\n",
       "             '3948': ['3948', '0605', '0003'],\n",
       "             '0804': ['0804', '3344', '4019', '0003'],\n",
       "             '3967': ['3967', '3391', '4019', '0003'],\n",
       "             '3656': ['3656', '3361', '0003'],\n",
       "             '2830': ['2830', '0804', '3344', '4019', '0003'],\n",
       "             '3324': ['3324', '0634', '3303', '4019', '0003'],\n",
       "             '0605': ['0605', '0003'],\n",
       "             '3386': ['3386', '3344', '4019', '0003'],\n",
       "             '0607': ['0607', '0605', '0003'],\n",
       "             '3361': ['3361', '0003'],\n",
       "             '3385': ['3385', '3382', '3361', '0003'],\n",
       "             '0153': ['0153', '0081', '3307', '4019', '0003'],\n",
       "             '3068': ['3068', '0003'],\n",
       "             '3444': ['3444', '3382', '3361', '0003'],\n",
       "             '3474': ['3474', '3316', '0003'],\n",
       "             '0102': ['0102', '0080', '3307', '4019', '0003'],\n",
       "             '3387': ['3387', '3070', '4019', '0003'],\n",
       "             '3315': ['3315', '0003'],\n",
       "             '3576': ['3576', '3297', '3070', '4019', '0003'],\n",
       "             '3384': ['3384', '3382', '3361', '0003'],\n",
       "             '3063': ['3063', '0605', '0003'],\n",
       "             '3415': ['3415', '3303', '4019', '0003'],\n",
       "             '0209': ['0209', '3336', '3314', '0003'],\n",
       "             '3303': ['3303', '4019', '0003'],\n",
       "             '3376': ['3376', '3344', '4019', '0003'],\n",
       "             '0820': ['0820', '0078', '3307', '4019', '0003'],\n",
       "             '4038': ['4038', '3697', '0610', '4019', '0003'],\n",
       "             '3939': ['3939', '3297', '3070', '4019', '0003'],\n",
       "             '3172': ['3172', '3391', '4019', '0003'],\n",
       "             '3837': ['3837', '3168', '3361', '0003'],\n",
       "             '3174': ['3174', '0610', '4019', '0003'],\n",
       "             '3941': ['3941', '3308', '0622', '3391', '4019', '0003'],\n",
       "             '3674': ['3674', '3656', '3361', '0003'],\n",
       "             '3518': ['3518', '3361', '0003'],\n",
       "             '3339': ['3339', '3277', '3344', '4019', '0003'],\n",
       "             '3697': ['3697', '0610', '4019', '0003'],\n",
       "             '3301': ['3301', '3070', '4019', '0003'],\n",
       "             '4030': ['4030', '3318', '0003'],\n",
       "             '0798': ['0798', '0114', '3321', '3307', '4019', '0003'],\n",
       "             '0621': ['0621', '3070', '4019', '0003'],\n",
       "             '3047': ['3047', '3070', '4019', '0003'],\n",
       "             '0176': ['0176', '3892', '3307', '4019', '0003'],\n",
       "             '3945': ['3945', '3391', '4019', '0003'],\n",
       "             '3321': ['3321', '3307', '4019', '0003'],\n",
       "             '0602': ['0602', '3307', '4019', '0003'],\n",
       "             '3388': ['3388', '3342', '3303', '4019', '0003'],\n",
       "             '2275': ['2275', '0082', '0081', '3307', '4019', '0003'],\n",
       "             '3338': ['3338', '3277', '3344', '4019', '0003'],\n",
       "             '4021': ['4021', '3391', '4019', '0003'],\n",
       "             '3416': ['3416', '3303', '4019', '0003'],\n",
       "             '0593': ['0593', '3382', '3361', '0003'],\n",
       "             '0218': ['0218', '3068', '0003'],\n",
       "             '3304': ['3304', '3344', '4019', '0003'],\n",
       "             '3334': ['3334', '3303', '4019', '0003'],\n",
       "             '3448': ['3448', '3382', '3361', '0003'],\n",
       "             '3511': ['3511', '0160', '3307', '4019', '0003'],\n",
       "             '0097': ['0097', '0077', '3307', '4019', '0003'],\n",
       "             '0077': ['0077', '3307', '4019', '0003'],\n",
       "             '3390': ['3390', '3344', '4019', '0003'],\n",
       "             '3391': ['3391', '4019', '0003'],\n",
       "             '2640': ['2640', '3303', '4019', '0003'],\n",
       "             '0089': ['0089', '0605', '0003'],\n",
       "             '4010': ['4010', '0003'],\n",
       "             '3417': ['3417', '3303', '4019', '0003'],\n",
       "             '3519': ['3519', '3361', '0003'],\n",
       "             '3418': ['3418', '3303', '4019', '0003'],\n",
       "             '3401': ['3401', '3303', '4019', '0003'],\n",
       "             '3943': ['3943', '0622', '3391', '4019', '0003'],\n",
       "             '3302': ['3302', '3344', '4019', '0003'],\n",
       "             '0634': ['0634', '3303', '4019', '0003'],\n",
       "             '3577': ['3577', '3303', '4019', '0003'],\n",
       "             '0208': ['0208', '0622', '3391', '4019', '0003'],\n",
       "             '0202': ['0202', '3344', '4019', '0003'],\n",
       "             '3378': ['3378', '3377', '3376', '3344', '4019', '0003'],\n",
       "             '3298': ['3298', '3391', '4019', '0003'],\n",
       "             '3293': ['3293', '0084', '3307', '4019', '0003'],\n",
       "             '0194': ['0194', '0622', '3391', '4019', '0003'],\n",
       "             '0084': ['0084', '3307', '4019', '0003'],\n",
       "             '3318': ['3318', '0003'],\n",
       "             '3300': ['3300', '3303', '4019', '0003'],\n",
       "             '0780': ['0780', '3070', '4019', '0003'],\n",
       "             '3056': ['3056', '3053', '3070', '4019', '0003'],\n",
       "             '3796': ['3796', '0622', '3391', '4019', '0003'],\n",
       "             '3379': ['3379', '3678', '0003'],\n",
       "             '0632': ['0632', '0080', '3307', '4019', '0003'],\n",
       "             '3534': ['3534', '3510', '0160', '3307', '4019', '0003'],\n",
       "             '3538': ['3538', '2814', '0081', '3307', '4019', '0003'],\n",
       "             '0108': ['0108', '0078', '3307', '4019', '0003'],\n",
       "             '0130': ['0130', '2814', '0081', '3307', '4019', '0003'],\n",
       "             '0736': ['0736', '2814', '0081', '3307', '4019', '0003'],\n",
       "             '3957': ['3957', '3361', '0003'],\n",
       "             '0128': ['0128', '0602', '3307', '4019', '0003'],\n",
       "             '0601': ['0601', '0108', '0078', '3307', '4019', '0003'],\n",
       "             '0123': ['0123', '0078', '3307', '4019', '0003'],\n",
       "             '3542': ['3542', '2814', '0081', '3307', '4019', '0003'],\n",
       "             '3510': ['3510', '0160', '3307', '4019', '0003'],\n",
       "             '0166': ['0166', '2814', '0081', '3307', '4019', '0003'],\n",
       "             '2814': ['2814', '0081', '3307', '4019', '0003'],\n",
       "             '0140': ['0140', '0108', '0078', '3307', '4019', '0003'],\n",
       "             '3120': ['3120', '0108', '0078', '3307', '4019', '0003'],\n",
       "             '0078': ['0078', '3307', '4019', '0003'],\n",
       "             '3922': ['3922', '0622', '3391', '4019', '0003'],\n",
       "             '0121': ['0121', '3391', '4019', '0003'],\n",
       "             '3520': ['3520', '3361', '0003'],\n",
       "             '3419': ['3419', '3303', '4019', '0003'],\n",
       "             '3305': ['3305', '3303', '4019', '0003'],\n",
       "             '3570': ['3570', '3315', '0003'],\n",
       "             '3393': ['3393', '3376', '3344', '4019', '0003'],\n",
       "             '3055': ['3055', '0625', '3053', '3070', '4019', '0003'],\n",
       "             '0099': ['0099', '0077', '3307', '4019', '0003'],\n",
       "             '3794': ['3794', '3656', '3361', '0003'],\n",
       "             '3320': ['3320', '0203', '3321', '3307', '4019', '0003'],\n",
       "             '3170': ['3170', '3168', '3361', '0003'],\n",
       "             '3523': ['3523', '3361', '0003'],\n",
       "             '3325': ['3325', '0634', '3303', '4019', '0003'],\n",
       "             '3395': ['3395', '3344', '4019', '0003'],\n",
       "             '3394': ['3394', '3376', '3344', '4019', '0003'],\n",
       "             '3420': ['3420', '3303', '4019', '0003'],\n",
       "             '3322': ['3322', '3303', '4019', '0003'],\n",
       "             '4027': ['4027', '3308', '0622', '3391', '4019', '0003'],\n",
       "             '3377': ['3377', '3376', '3344', '4019', '0003'],\n",
       "             '3277': ['3277', '3344', '4019', '0003'],\n",
       "             '0080': ['0080', '3307', '4019', '0003'],\n",
       "             '0196': ['0196', '0080', '3307', '4019', '0003'],\n",
       "             '0157': ['0157', '0080', '3307', '4019', '0003'],\n",
       "             '0160': ['0160', '3307', '4019', '0003'],\n",
       "             '3168': ['3168', '3361', '0003'],\n",
       "             '3524': ['3524', '3361', '0003'],\n",
       "             '4028': ['4028', '3168', '3361', '0003'],\n",
       "             '0154': ['0154', '0081', '3307', '4019', '0003'],\n",
       "             '3372': ['3372', '3316', '0003'],\n",
       "             '2269': ['2269', '3315', '0003'],\n",
       "             '1317': ['1317', '3070', '4019', '0003'],\n",
       "             '0122': ['0122', '0622', '3391', '4019', '0003'],\n",
       "             '3175': ['3175', '0654', '0077', '3307', '4019', '0003'],\n",
       "             '0081': ['0081', '3307', '4019', '0003'],\n",
       "             '0082': ['0082', '0081', '3307', '4019', '0003'],\n",
       "             '3421': ['3421', '3303', '4019', '0003'],\n",
       "             '3895': ['3895', '3070', '4019', '0003'],\n",
       "             '3371': ['3371', '3314', '0003'],\n",
       "             '2259': ['2259', '3070', '4019', '0003'],\n",
       "             '3396': ['3396', '3303', '4019', '0003'],\n",
       "             '0637': ['0637', '3299', '3070', '4019', '0003'],\n",
       "             '3452': ['3452', '3382', '3361', '0003'],\n",
       "             '2840': ['2840', '3303', '4019', '0003'],\n",
       "             '0749': ['0749', '0078', '3307', '4019', '0003'],\n",
       "             '3308': ['3308', '0622', '3391', '4019', '0003'],\n",
       "             '3342': ['3342', '3303', '4019', '0003'],\n",
       "             '3414': ['3414', '3303', '4019', '0003'],\n",
       "             '3575': ['3575', '3303', '4019', '0003'],\n",
       "             '3422': ['3422', '3303', '4019', '0003'],\n",
       "             '3966': ['3966', '3376', '3344', '4019', '0003'],\n",
       "             '3397': ['3397', '3303', '4019', '0003'],\n",
       "             '0781': ['0781', '3070', '4019', '0003'],\n",
       "             '3673': ['3673', '3168', '3361', '0003'],\n",
       "             '0769': ['0769', '3071', '0003'],\n",
       "             '2828': ['2828', '3382', '3361', '0003'],\n",
       "             '3500': ['3500', '3070', '4019', '0003']})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shortest_path(topic_dict, topic):\n",
    "    \n",
    "    queue = [(topic, 0, [topic])]\n",
    "    visited = set()\n",
    "    \n",
    "    while queue:\n",
    "        current_topic, distance, path = queue.pop(0)\n",
    "        \n",
    "        if current_topic == '0003':\n",
    "            return path\n",
    "        \n",
    "        visited.add(current_topic)\n",
    "        \n",
    "        if current_topic in topic_dict:\n",
    "            parents = topic_dict[current_topic]\n",
    "            \n",
    "            for parent in parents:\n",
    "                if parent not in visited:\n",
    "                    queue.append((parent, distance + 1, path + [parent]))\n",
    "    \n",
    "    return []  # If the root topic is not found\n",
    "\n",
    "shortest_paths = defaultdict(list)\n",
    "\n",
    "for topic in topic_subtree_dict.keys():\n",
    "    shortest_paths[topic] = shortest_path(topic_dict, topic)\n",
    "\n",
    "shortest_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights for each row\n",
    "def calculate_weights(tree, term1, term2, paths=shortest_paths):\n",
    "\n",
    "    # Weight 1: Distance from root\n",
    "    steps_to_term1 = shortest_distance(tree, term1)\n",
    "    steps_to_term2 = shortest_distance(tree, term2)\n",
    "\n",
    "    # determine the steps between the two terms\n",
    "    def steps_between_terms(paths, topic1, topic2):\n",
    "        path1 = paths[topic1]\n",
    "        path2 = paths[topic2]\n",
    "\n",
    "        index1 = index2 = 0\n",
    "\n",
    "        for i, (n1, n2) in enumerate(zip(path1, path2)):\n",
    "            if n1 != n2:\n",
    "                break\n",
    "\n",
    "            index1 = i + 1\n",
    "            index2 = i + 1\n",
    "\n",
    "        return len(path1) - index1 + len(path2) - index2\n",
    "\n",
    "    steps_between = steps_between_terms(paths, term1, term2)\n",
    "\n",
    "    # Assuming term1 is ground truth and term2 is prediction\n",
    "    if steps_to_term1 < steps_to_term2:\n",
    "        weight1 = 1 - (1 / steps_to_term1)\n",
    "        weight2 = (1 / steps_between)\n",
    "    else:\n",
    "        weight1 = 1 - (1 / steps_to_term2)\n",
    "        weight2 = -1 / steps_between\n",
    "    \n",
    "    weight = weight1 + abs(weight2)\n",
    "\n",
    "    return weight, (weight1, weight2)\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    ground_truth = row['Exclusive Ground Truth']\n",
    "    prediction = row['Exclusive Predictions']\n",
    "\n",
    "    weights = []\n",
    "    num_positive_w2 = num_negative_w2 = 0\n",
    "    for truth_label in ground_truth:\n",
    "        for pred_label in prediction:\n",
    "            truth_topic, pred_topic = plabel_topic_dict[truth_label], plabel_topic_dict[pred_label]\n",
    "            # If labels are not in the same subtree\n",
    "            if not set(topic_subtree_dict[pred_topic]) & set(topic_subtree_dict[truth_topic]):\n",
    "                continue\n",
    "            total_weight, (w1, w2) = calculate_weights(topic_dict, truth_topic, pred_topic)\n",
    "            weights.append(total_weight)\n",
    "\n",
    "            if w2 >= 0:\n",
    "                num_positive_w2 += 1\n",
    "            elif w2 < 0:\n",
    "                num_negative_w2 += 1\n",
    "    \n",
    "    data.loc[idx, 'Weight'] = sum(weights) / max(1, len(weights)) + row['Jaccard Similarity']\n",
    "    # data.loc[idx, 'Broadness Score'] = num_positive_w2 / (num_positive_w2 + num_negative_w2\n",
    "    try:\n",
    "        data.loc[idx, 'Broadness Score'] = num_positive_w2 / (num_negative_w2)\n",
    "    except:\n",
    "        data.loc[idx, 'Broadness Score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights for prediction number bias\n",
    "\n",
    "# data['Adjusted Weights'] = data['Weight'] * (data['Ground Truth'].apply(len) / data['Predictions'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overprediction penalty'] = data['Ground Truth'].apply(len) / data['Predictions'].apply(len)\n",
    "data['penalty'] = data['overprediction penalty'].apply(lambda x: 1 if x>1 else x)\n",
    "data['Adjusted Weights'] = data['Weight'] * data['penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('outputs/updated_scoring_results_immport.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nde_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
