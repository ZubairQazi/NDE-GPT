{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Gathering\n",
    "\n",
    "Note: This is for the production API of niad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(\"https://api.data.niaid.nih.gov/v1/query?=&q=*pmid*&extra_filter=&size=1000&from=0&sort=_score&use_metadata_score=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = results.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmids = []\n",
    "for hits in data['hits']:\n",
    "    if type(hits['citation']) is list:\n",
    "        pmids.append(hits['citation'][0]['pmid'])\n",
    "\n",
    "pmids = np.unique(pmids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gathered {len(pmids)} unique PMIDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting MeSH Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "\n",
    "Entrez.email = \"zqazi@scripps.edu\"\n",
    "\n",
    "dataset = pd.DataFrame(columns=['PMID', 'Abstract', 'MeSH Terms'])\n",
    "\n",
    "def get_mesh_terms(pmid):\n",
    "\n",
    "    try:\n",
    "        # Fetch article details using the PMID\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=pmid, retmode=\"xml\")\n",
    "        article_data = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        # Extract MeSH terms from the article data\n",
    "        mesh_terms = []\n",
    "        abstract = None\n",
    "        if \"PubmedArticle\" in article_data:\n",
    "            for article in article_data[\"PubmedArticle\"]:\n",
    "                if \"MeshHeadingList\" in article[\"MedlineCitation\"]:\n",
    "                    mesh_headings = article[\"MedlineCitation\"][\"MeshHeadingList\"]\n",
    "                    for heading in mesh_headings:\n",
    "                        descriptor_name = heading[\"DescriptorName\"]\n",
    "                        mesh_terms.append(descriptor_name)\n",
    "                    \n",
    "                    # Get abstract if there are MeSH terms\n",
    "                    if \"Abstract\" in article[\"MedlineCitation\"]['Article']:\n",
    "                        abstract = article[\"MedlineCitation\"]['Article'][\"Abstract\"][\"AbstractText\"][0]\n",
    "\n",
    "        return abstract, mesh_terms\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "for idx, pmid_to_query in enumerate(tqdm(pmids)):\n",
    "\n",
    "    # Get MeSH terms for the specified PMID\n",
    "    abstract, mesh_terms = get_mesh_terms(pmid_to_query)\n",
    "\n",
    "    if mesh_terms and abstract:\n",
    "        # print(f\"MeSH terms for PMID {pmid_to_query}:\\n\")\n",
    "        # for term in mesh_terms_result:\n",
    "        #     print(term)\n",
    "        \n",
    "        # {'PMID': pmid_to_query, 'Abstract': str(abstract), 'MeSH Terms': [str(term) for term in mesh_terms]}\n",
    "        dataset.loc[len(dataset.index)] = [pmid_to_query, abstract, [str(term) for term in np.unique(mesh_terms)]]\n",
    "\n",
    "    if not mesh_terms and not abstract:\n",
    "        print(f\"Failed to retrieve MeSH terms AND Abstract for PMID {pmid_to_query}.\")\n",
    "    elif not mesh_terms:\n",
    "        print(f\"Failed to retrieve MeSH terms for PMID {pmid_to_query}.\")\n",
    "    elif not abstract:\n",
    "        print(f\"Failed to retrieve Abstract for PMID {pmid_to_query}.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping MeSH terms to EDAM ontology\n",
    "\n",
    "First, a proof of concept..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text2term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam_ontology = text2term.cache_ontology(\"https://data.bioontology.org/ontologies/EDAM/submissions/44/download?apikey=8b5b7825-538d-40e0-9e9e-5ab9274a9aeb\", \"EDAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_terms = text2term.map_terms([str(term) for term in dataset.iloc[0]['MeSH Terms']], \"EDAM\", use_cache=True)\n",
    "mapped_terms[['Source Term', 'Mapped Term Label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map All MeSH Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mesh_to_edam(mesh_terms):\n",
    "    mapped_terms = text2term.map_terms(mesh_terms, \"EDAM\", use_cache=True)\n",
    "\n",
    "    return mapped_terms['Mapped Term Label'].unique().tolist()\n",
    "\n",
    "dataset['EDAM Topics'] = dataset['MeSH Terms'].apply(lambda terms: convert_mesh_to_edam(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['MeSH Terms', 'EDAM Topics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Any unmapped MeSH Terms?: \", dataset['EDAM Topics'].isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2term.clear_cache(\"EDAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the validity of EDAM topics\n",
    "Based on the OpenAI API input token limit, we can't pass in every EDAM term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EDAM/edam_topics.txt', 'r') as edam_file:\n",
    "    edam_topics = edam_file.readlines()\n",
    "\n",
    "edam_topics = [topic.strip() for topic in edam_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_true = dataset.loc[dataset['EDAM Topics'].apply(lambda edam_list: not all(term in edam_topics for term in edam_list))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices_true:\n",
    "    edam_list = dataset.loc[index, 'EDAM Topics']\n",
    "    terms_not_in_edam_topics = [term for term in edam_list if term not in edam_topics]\n",
    "    \n",
    "    print(f\"Index {index}: Terms not in edam_topics: {terms_not_in_edam_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(index=indices_true, axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check for N/A values:\")\n",
    "\n",
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of entries: \", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(input(\"Enter file path and name: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
