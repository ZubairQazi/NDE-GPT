{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'outputs/dryad.csv'\n",
    "\n",
    "data = pd.read_csv(DATA_PATH, lineterminator=\"\\n\")\n",
    "\n",
    "print(f'Loaded dataset with {len(data)} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('EDAM/edam_topics.txt', 'r') as f:\n",
    "    edam_topics = [topic.strip() for topic in f.readlines()]\n",
    "\n",
    "quoted_topics = [topic for topic in edam_topics if topic.startswith('\"') and topic.endswith('\"')]\n",
    "\n",
    "# Remove quotes\n",
    "edam_topics = [topic[1:-1] if topic.startswith('\"') and topic.endswith('\"') else topic for topic in edam_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Outputs\n",
    "\n",
    "Split outputs on tab, and check for other separators that GPT may have used in error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Predictions'] = data['Predictions'].str.replace('\\\\t', '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_topics(topics):\n",
    "    cleaned_topics = [topic.strip() for topic in topics.split('\\t')]\n",
    "    for i in range(len(cleaned_topics)):\n",
    "        for quoted_topic in quoted_topics:\n",
    "            if quoted_topic.replace('\\\"', '').lower() in cleaned_topics[i].lower():\n",
    "                cleaned_topics[i] = cleaned_topics[i].replace(quoted_topic.replace('\\\"', ''), quoted_topic)\n",
    "                break\n",
    "            else:\n",
    "                cleaned_topics[i] = cleaned_topics[i].replace('\\\"', '')\n",
    "    return cleaned_topics\n",
    "\n",
    "data['Predictions'] = data['Predictions'].apply(split_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separators = ['    ', '   ', '  ', '\\n', '<TAB>', 'TAB', '<tab>', '(tab)', '<Tab>', '[tab]', '▪️', '(Tab)', '\\xa0\\xa0\\xa0\\xa0', '\\xa0', '\\u2003', '、', '\\x0b', '\\x0c', ';', '.', '--', '-', '–', '_', '\\\\', '\\\\n', '/', '@', '|', '\\r', '+', '<', '>']\n",
    "\n",
    "# Join the separators with the regex OR operator |\n",
    "sep_pattern = '|'.join(map(re.escape, separators))\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    split_list = [re.split(sep_pattern, pred) for pred in data['Predictions'][i]]\n",
    "    # Flatten the list\n",
    "    data['Predictions'][i] = [item for sublist in split_list for item in sublist]\n",
    "\n",
    "data['Predictions'] = data['Predictions'].apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "data['Predictions'] = data['Predictions'].apply(lambda x: [re.sub(r'Category \\d+:', '', pred) for pred in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_one_dimensional = all(isinstance(pred, str) for preds in data['Predictions'] for pred in preds)\n",
    "print(is_one_dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Capture any weirdly formatted outputs (using the wrong separators)\n",
    "\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('    ') if 0 < len(x) <= 1 and '    ' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('   ') if 0 < len(x) <= 1 and '   ' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('  ') if 0 < len(x) <= 1 and '  ' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\n') if 0 < len(x) <= 1 and '\\n' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('<TAB>') if 0 < len(x) <= 1 and '<TAB>' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('TAB') if 0 < len(x) <= 1 and 'TAB' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('<tab>') if 0 < len(x) <= 1 and '<tab>' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('(tab)') if 0 < len(x) <= 1 and '(tab)' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('<Tab>') if 0 < len(x) <= 1 and '<Tab>' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('[tab]') if 0 < len(x) <= 1 and '[tab]' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('▪️') if 0 < len(x) <= 1 and '▪️' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('(Tab)') if 0 < len(x) <= 1 and '<Tab>' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\xa0\\xa0\\xa0\\xa0') if 0 < len(x) <= 1 and '\\xa0\\xa0\\xa0\\xa0' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\xa0') if 0 < len(x) <= 1 and '\\xa0' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\u2003') if 0 < len(x) <= 1 and '\\u2003' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('、') if 0 < len(x) <= 1 and '、' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\x0b') if 0 < len(x) <= 1 and '\\x0b' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\x0c') if 0 < len(x) <= 1 and '\\x0c' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split(';') if 0 < len(x) <= 1 and ';' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('.') if 0 < len(x) <= 1 and '.' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('--') if 0 < len(x) <= 1 and '--' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('-') if 0 < len(x) <= 1 and '-' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('–') if 0 < len(x) <= 1 and '–' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('_') if 0 < len(x) <= 1 and '_' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\\\') if 0 < len(x) <= 1 and '\\\\' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\\\n') if 0 < len(x) <= 1 and '\\\\n' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('/') if 0 < len(x) <= 1 and '/' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('@') if 0 < len(x) <= 1 and '@' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('|') if 0 < len(x) <= 1 and '|' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('\\r') if 0 < len(x) <= 1 and '\\r' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('+') if 0 < len(x) <= 1 and '+' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('<') if 0 < len(x) <= 1 and '<' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split('>') if 0 < len(x) <= 1 and '>' in list(x)[0] else x)\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: [pred.strip() for pred in csv.reader([list(x)[0]],skipinitialspace=True, delimiter=',', quotechar='\"').__next__()])\n",
    "# data['Predictions'] = data['Predictions'].apply(lambda x: [re.sub(r'Category \\d+:', '', pred) for pred in x])\n",
    "# # data['Predictions'] = data['Predictions'].apply(lambda x: list(x)[0].split(', ') if len(x) <= 1 and ', ' in list(x)[0] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any of the quoted topics, or their equivalent without quotes, \n",
    "# are in any of the prediction sets with length less than or equal to 1. \"\"\n",
    "# If there is, then add the quotes back in if they don't have them,\n",
    "#  and then split on commas while avoiding anything inside quotes\n",
    "def process_predictions(predictions):\n",
    "    processed_predictions = []\n",
    "    for prediction in predictions:\n",
    "        formatted = False\n",
    "        for topic in quoted_topics:\n",
    "            formatted_topic = topic.replace('\\\"', '')\n",
    "            if formatted_topic in prediction:\n",
    "                processed_prediction = prediction.replace(formatted_topic, f'{topic}')\n",
    "                processed_predictions.append(processed_prediction)\n",
    "                formatted = True\n",
    "                break\n",
    "        if not formatted:\n",
    "            processed_predictions.append(prediction)\n",
    "        \n",
    "    final_predictions = []\n",
    "    for prediction in processed_predictions:\n",
    "        if '\\\"' in prediction:\n",
    "            parts = re.findall(r'[^\"]+|\"[^\"]+\"', prediction)\n",
    "            final_predictions.extend(parts)\n",
    "        else:\n",
    "            final_predictions.extend([pred.strip() for pred in prediction.split(',')])\n",
    "    return set(final_predictions)\n",
    "\n",
    "data['Predictions'] = data['Predictions'].apply(process_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_predictions = data[data['Predictions'].apply(len) <= 1]['Predictions']\n",
    "\n",
    "# Filter out any expected predictions, so we can see only the unexpected ones\n",
    "unexpected_predictions = []\n",
    "for original_index, pred_set in filtered_predictions.items():\n",
    "    lst = list(pred_set)\n",
    "    if len(lst) == 0:\n",
    "        continue\n",
    "    prediction = lst[0]\n",
    "    if '\\\"' not in prediction and ' ' in prediction and prediction not in edam_topics:\n",
    "        unexpected_predictions.append((original_index, prediction))\n",
    "\n",
    "# Print the unexpected predictions and their corresponding original indices\n",
    "count = len(unexpected_predictions)\n",
    "print(f\"Number of unexpected predictions: {count}\")\n",
    "for original_index, prediction in unexpected_predictions:\n",
    "    print(f\"Original Index: {original_index}, Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hallucinations\n",
    "\n",
    "Filter out topics not in the EDAM topics list. The filtered topics may be matched to a topic or synonym->topic in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Hallucinations'] = data['Predictions'].apply(lambda preds: set([pred.replace('.', '').replace('\\\"', '') for pred in preds if pred.replace('.', '').replace('\\\"', '') not in edam_topics]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Predictions'] = data['Predictions'].apply(lambda preds: set([pred.replace('.', '').replace('\\\"', '') for pred in preds if pred.replace('.', '').replace('\\\"', '') in edam_topics]))\n",
    "data['Predictions'] = data.apply(lambda row: set([topic for topic in row['Predictions'] if topic not in row['Hallucinations']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonym matching\n",
    "\n",
    "Check for mispelled/misformatted topics or synonyms using levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam = pd.read_csv('EDAM/EDAM.csv')\n",
    "\n",
    "edam = edam[edam['Class ID'].str.contains('topic')].reset_index(drop=True)\n",
    "# edam['Preferred Label'].apply(lambda topic: topic.replace('\\\"', ''))\n",
    "edam = edam[edam['Preferred Label'].isin([topic.replace('\\\"', '') for topic in edam_topics])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam['Synonyms'] = edam['Synonyms'].fillna('').apply(lambda x: x.split('|') if x != '' else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_topics = set([topic.replace('\\\"', '') for topic in edam_topics]) - set(edam['Preferred Label'])\n",
    "missing_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "\n",
    "for index, row in edam.iterrows():\n",
    "    for synonym in row['Synonyms']:\n",
    "        synonym_dict[synonym] = row['Preferred Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "hallucinations = data['Hallucinations']\n",
    "\n",
    "matched_topics = {}\n",
    "\n",
    "for hallucination_set in tqdm(hallucinations):\n",
    "    for hallucination in hallucination_set:\n",
    "        if hallucination in matched_topics:\n",
    "            continue\n",
    "        matched = False\n",
    "        # First check for a match in the topics list\n",
    "        sorted_topics = sorted(edam_topics, key=lambda topic: Levenshtein.distance(hallucination, topic))\n",
    "        for topic in sorted_topics:\n",
    "            distance = Levenshtein.distance(hallucination, topic)\n",
    "            if  0 < distance <= 2:\n",
    "                matched_topics[hallucination] = topic\n",
    "                matched = True\n",
    "                break\n",
    "        \n",
    "        # If the hallucination has already been matched, skip to the next hallucination\n",
    "        if matched:\n",
    "            continue\n",
    "        \n",
    "        # If no match in the topics list, look through the available synonyms\n",
    "        sorted_synonyms = sorted(synonym_dict.keys(), key=lambda topic: Levenshtein.distance(hallucination, topic))\n",
    "        for topic in sorted_synonyms:\n",
    "            distance = Levenshtein.distance(hallucination, topic)\n",
    "            if 0 <= distance <= 1:\n",
    "                matched_topics[hallucination] = synonym_dict[topic]\n",
    "                matched = True\n",
    "                break     \n",
    "\n",
    "        if matched:\n",
    "            continue\n",
    "\n",
    "        for topic in sorted_topics:\n",
    "            if topic.lower() in hallucination.lower().split():\n",
    "                matched_topics[hallucination] = topic\n",
    "                break\n",
    "        # No break reached\n",
    "        else:\n",
    "            for topic in sorted_synonyms:\n",
    "                if topic.lower() in hallucination.lower().split():\n",
    "                    matched_topics[hallucination] = synonym_dict[topic]\n",
    "                    break\n",
    "\n",
    "matched_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if len(row['Hallucinations']) > 0:\n",
    "        for hallucination in list(row['Hallucinations']):\n",
    "            if hallucination in matched_topics:\n",
    "                print(f\"'{hallucination}' in row {index} matches topic '{matched_topics[hallucination]}'\")\n",
    "                data.at[index, 'Predictions'].add(matched_topics[hallucination])\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Hallucinations'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add quotes back in for the predictions with commas (i.e, \"Data submission, annotation, and curation\")\n",
    "data['Predictions'] = data['Predictions'].apply(lambda preds: [f'\"{pred}\"' if f'\"{pred}\"' in quoted_topics else pred for pred in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Hallucinations'].apply(len) > 0][['Predictions', 'Hallucinations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Predictions'] = data['Predictions'].apply(lambda lst: set(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.basename(DATA_PATH).replace('.', '_processed.')\n",
    "\n",
    "data.to_csv(f'outputs/{file_name}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nde_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
