{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT for Topic Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "\n",
    "import openai\n",
    "from langchain.llms import OpenAI \n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "EDAM topics, prompt, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = config[\"api_keys\"][\"openai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(input(\"Enter testing dataset path: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/prompt_template.txt', 'r') as template_file:\n",
    "    template = template_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input(\"Enter EDAM topics file:\"), 'r') as edam_file:\n",
    "    full_edam_topics = edam_file.readlines()\n",
    "\n",
    "full_edam_topics = [topic.strip() for topic in full_edam_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add EDAM topics to prompt template\n",
    "\n",
    "formatted_topics = \"\\n\".join(full_edam_topics)\n",
    "template = template.replace(\"<topics>\", formatted_topics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Remove non-unique terms from each row's EDAM topic list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(dataset['EDAM Topics'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "plt.hist(dataset['MeSH Terms'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Topics / Terms')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend(['EDAM', 'MeSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total MeSH Terms:\", len(list(dataset.iloc[0]['MeSH Terms'])))\n",
    "print(\"Unique MeSH Terms:\", len(np.unique(list(dataset.iloc[0]['MeSH Terms']))))\n",
    "print()\n",
    "print(\"Total EDAM Topics:\", len(list(dataset.iloc[0]['EDAM Topics'])))\n",
    "print(\"Unique EDAM Topics:\", len(np.unique(list(dataset.iloc[0]['EDAM Topics']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['MeSH Terms'] = dataset['MeSH Terms'].apply(lambda mesh_list: np.unique(ast.literal_eval((mesh_list))))\n",
    "dataset['EDAM Topics'] = dataset['EDAM Topics'].apply(lambda edam_list: np.unique(ast.literal_eval((edam_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(dataset['EDAM Topics'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "plt.hist(dataset['MeSH Terms'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Topics / Terms')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend(['EDAM', 'MeSH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove any topics not in the EDAM Topics list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Filtered EDAM'] = dataset['EDAM Topics'].apply(lambda x: [item for item in x if item in full_edam_topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(dataset['EDAM Topics'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "plt.hist(dataset['Filtered EDAM'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Topics / Terms')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend(['EDAM', 'Filtered EDAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any issues during filtering (missed topics, etc)\n",
    "\n",
    "indices_true = dataset.loc[dataset['Filtered EDAM'].apply(lambda edam_list: not all(term in full_edam_topics for term in edam_list))].index\n",
    "\n",
    "for index in indices_true:\n",
    "    edam_list = dataset.loc[index, 'Filtered EDAM']\n",
    "    terms_not_in_edam_topics = [term for term in edam_list if term not in full_edam_topics]\n",
    "    \n",
    "    print(f\"Index {index}: Terms not in edam_topics: {terms_not_in_edam_topics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API\n",
    "\n",
    "Let's start with a proof of concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = dataset.sample(n=1)\n",
    "\n",
    "index = random_sample.index[0]\n",
    "description, abstract, paper_edam_topics = random_sample[['Description', 'Abstract', 'Filtered EDAM']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "# prompt = template.replace('<description>', description).replace('<num_terms>', str(len(paper_edam_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=f\"You're a helpful assistant.\"),\n",
    "    HumanMessage(content=prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "gpt_output = ''\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chat.invoke(messages)\n",
    "    for chunk in chat.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        gpt_output += chunk.content\n",
    "    print(\"\\n===========CALLBACK: ==========\\n\")\n",
    "    print(cb)\n",
    "    print(\"\\n=============\\n\")\n",
    "\n",
    "\n",
    "# chat = OpenAI(\n",
    "#     model_name='text-davinci-003',\n",
    "#     openai_api_key = openai_api_key,\n",
    "#     temperature=0.75\n",
    "# )\n",
    "\n",
    "# gpt_output = ''\n",
    "\n",
    "# with get_openai_callback() as cb:\n",
    "#     chat.invoke(messages)\n",
    "#     for chunk in chat.stream(messages):\n",
    "#         print(chunk, end=\"\", flush=True)\n",
    "#         gpt_output += chunk\n",
    "#     print(\"\\n===========CALLBACK: ==========\\n\")\n",
    "#     print(cb)\n",
    "#     print(\"\\n=============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_edam = 0\n",
    "\n",
    "true_topics = dataset.iloc[index]['Filtered EDAM']\n",
    "num_correct = 0\n",
    "\n",
    "for topic in gpt_output.strip().split(', '):\n",
    "    if topic not in full_edam_topics:\n",
    "        print(topic)\n",
    "        not_in_edam += 1\n",
    "        continue\n",
    "\n",
    "    if topic in true_topics:\n",
    "        num_correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPT-outputted topics not in EDAM:\", not_in_edam)\n",
    "print(\"# Correct topics from GPT:\", num_correct)\n",
    "print(\"# Incorrect topics from GPT:\", len(true_topics) - num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt_output, '\\n')\n",
    "print(', '.join(true_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: It seems as though GPT is not able to capture relevant topics given the entire list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPT to capture major subtopics (Biology, Medicine, etc.)\n",
    "\n",
    "We will see if GPT can capture the general topics of each data entry. Then we can pass the relevant subtopics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bioportal.bioontology.org/ontologies/EDAM/?p=classes&conceptid=http%3A%2F%2Fedamontology.org%2Ftopic_0003\n",
    "\n",
    "Biosciences - 4019\n",
    "\n",
    "Chemistry - 3314\n",
    "\n",
    "Computer science - 3316\n",
    "\n",
    "Data management - 3071\n",
    "\n",
    "Environmental Sciences - 3855\n",
    "\n",
    "Informatics - 0605\n",
    "\n",
    "Open science - 4010\n",
    "\n",
    "Physics - 3318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edam_data = pd.read_csv(\"EDAM/EDAM.csv\")\n",
    "\n",
    "edam_data = edam_data[edam_data['Parents'].str.contains(\"http://edamontology.org/topic_\")]\n",
    "edam_data['Parents #'] = edam_data['Parents'].str.extractall(r'topic_(\\d+)').groupby(level=0).agg(lambda parents: parents.tolist())\n",
    "edam_data['Topic #'] = edam_data['Class ID'].apply(lambda url: url.split('topic_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "topics = ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318', '3361', '3068', '3678', '3315']\n",
    "\n",
    "subtopics = defaultdict(lambda: [])\n",
    "\n",
    "def get_children_topics(parent_id):\n",
    "    # children_ids = edam_data[edam_data['Parents'].str.contains(parent_id)]['Class ID'].apply(lambda url: url.split('topic_')[1]).to_list()\n",
    "    children_ids = edam_data[edam_data['Parents #'].apply(\\\n",
    "        lambda parent_ids: parent_id in parent_ids)]['Topic #'].to_list()\n",
    "    \n",
    "    if not len(children_ids):\n",
    "        return []\n",
    "    \n",
    "    # print(parent_id, children_ids)\n",
    "    \n",
    "    grandchildren = []\n",
    "    for child_id in children_ids:\n",
    "        grandchildren.append(get_children_topics(child_id))\n",
    "    \n",
    "    children_ids.append(grandchildren)\n",
    "    return children_ids\n",
    "\n",
    "for parent_topic in topics:\n",
    "    subtopics[parent_topic] = get_children_topics(parent_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    flattened = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "\n",
    "# Flatten each value in the dictionary\n",
    "subtopics = {key: flatten_list(value) for key, value in subtopics.items()}\n",
    "\n",
    "print()\n",
    "for key, value in subtopics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_to_remove = ['3361', '3068', '3678', '3315']\n",
    "topics_to_keep = ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318']\n",
    "\n",
    "for key in ['3361', '3068', '3678', '3315']:\n",
    "    topics_to_remove.extend(subtopics[key])\n",
    "\n",
    "for key in ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318']:\n",
    "    topics_to_keep.extend(subtopics[key])\n",
    "\n",
    "topics_to_remove, topics_to_keep = set(topics_to_remove), set(topics_to_keep)\n",
    "\n",
    "print('Number of Topics to remove: ', len([item for item in topics_to_remove if item not in topics_to_keep]))\n",
    "\n",
    "edam_data = edam_data[~edam_data['Topic #'].apply(lambda topic: topic in topics_to_remove and topic not in topics_to_keep)]\n",
    "\n",
    "# Remove the unnecessary topics =\n",
    "for topic in ['3361', '3068', '3678', '3315']:\n",
    "    del subtopics[topic]\n",
    "\n",
    "print()\n",
    "for key, value in subtopics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_topics = defaultdict(lambda: set())\n",
    "\n",
    "for key, values in subtopics.items():\n",
    "    for value in values:\n",
    "        parent_topics[value].add(key)\n",
    "\n",
    "\n",
    "for key, value in parent_topics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topics = {}\n",
    "\n",
    "for topic in ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318']:\n",
    "    main_topics[topic] = edam_data[edam_data['Topic #'] == topic]['Preferred Label'].values[0]\n",
    "\n",
    "main_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam_data['Parent Topics'] = edam_data['Topic #'].apply(lambda topic:[main_topics[parent_topic] for parent_topic in parent_topics[topic]])\n",
    "edam_data['Parent Topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Topic Category'] = dataset['Filtered EDAM'].apply(lambda edam_list: [edam_data[edam_data['Preferred Label'] == topic]['Parent Topics'].values[0] for topic in edam_list])\\\n",
    "    .apply(lambda parent_list: set([item for sublist in parent_list for item in sublist]))\n",
    "\n",
    "dataset['Topic Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT for topic categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/prompt_template.txt', 'r') as template_file:\n",
    "    template = template_file.read()\n",
    "\n",
    "formatted_topics = \"\\n\".join(main_topics.values())\n",
    "template = template.replace(\"<topics>\", formatted_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(generated_topics, true_topics):\n",
    "    num_correct = 0\n",
    "\n",
    "    for topic in generated_topics.strip().split(', '):\n",
    "        if topic in true_topics:\n",
    "            num_correct += 1\n",
    "    \n",
    "    return num_correct / len(true_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(chat, dataset, truth_column='Topic Category', iterations=10, seed=54):\n",
    "    cost, accuracies = 0, []\n",
    "    io_pairs = []\n",
    "\n",
    "    random_samples = dataset.sample(n=iterations, random_state=seed)\n",
    "    \n",
    "    for idx, random_sample in tqdm(random_samples.iterrows()):\n",
    "\n",
    "        index = random_sample.index[0]\n",
    "        _, abstract, paper_edam_topics = random_sample.loc[['Description', 'Abstract', truth_column]]\n",
    "\n",
    "        prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=f\"Generate a comma-separated list of relevant EDAM topics based on the provided abstract and topic categories.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "\n",
    "        gpt_output = ''\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            chat.invoke(messages)\n",
    "            for chunk in chat.stream(messages):\n",
    "                if type(chat) == ChatOpenAI:\n",
    "                    gpt_output += chunk.content\n",
    "                elif type(chat) == OpenAI:\n",
    "                    gpt_output += chunk\n",
    "            \n",
    "            cost += float(str(cb).split('$')[1])\n",
    "\n",
    "        try:\n",
    "            true_topics = dataset.iloc[index][truth_column]\n",
    "\n",
    "            accuracies.append(get_accuracy(gpt_output, true_topics))\n",
    "        except:\n",
    "            print('Error encountered at index', index)\n",
    "\n",
    "        io_pairs.append([abstract, ', '.join(true_topics), gpt_output])\n",
    "\n",
    "    print('Average Accuracy:', np.mean(accuracies))\n",
    "    print('Total Cost ($):', cost)\n",
    "\n",
    "    return accuracies, cost, io_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, _ = test(chat, dataset, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = OpenAI(\n",
    "    model_name='text-davinci-003',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, _ = test(chat, dataset, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, _ = test(chat, dataset, iterations=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double num_topics \n",
    "\n",
    "Attempting to see if GPT will eventually get the correct topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = dataset.sample(n=1)\n",
    "\n",
    "index = random_sample.index[0]\n",
    "description, abstract, paper_edam_topics = random_sample[['Description', 'Abstract', 'Filtered EDAM']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics) * 2))\n",
    "# prompt = template.replace('<description>', description).replace('<num_terms>', str(len(paper_edam_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=f\"You're a helpful assistant.\"),\n",
    "    HumanMessage(content=prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "gpt_output = ''\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chat.invoke(messages)\n",
    "    for chunk in chat.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        gpt_output += chunk.content\n",
    "    print(\"\\n===========CALLBACK: ==========\\n\")\n",
    "    print(cb)\n",
    "    print(\"\\n=============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(gpt_output, paper_edam_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abstract, '\\n')\n",
    "print(gpt_output)\n",
    "print(', '.join(random_sample['Filtered EDAM'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some potential, but requires further exploration. The main question to focus on is the definition of success, and how to measure whether the predicted topics are valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with 50 training samples for fine-tuning. (https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "training_data = dataset.sample(n=n, replace=False, random_state=50)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"datasets/finetune-data-{n}.jsonl\", 'w') as file:\n",
    "    for idx, row in training_data.iterrows():\n",
    "        description, abstract, paper_edam_topics = row[['Description', 'Abstract', 'Filtered EDAM']]\n",
    "        prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "\n",
    "        json_data = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Generate a comma-separated list of relevant EDAM topics based on the provided abstract and topic categories.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "                {\"role\": \"assistant\", \"content\": ', '.join(paper_edam_topics)}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        file.write(json.dumps(json_data))\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```Chat_finetuning_data_prep.ipynb``` to check for any errors in the data and to get the cost estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "fileobj = client.files.create(\n",
    "  file=open(f\"datasets/finetune-data-{n}.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "fileobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftjob = client.fine_tuning.jobs.create(\n",
    "  training_file=fileobj.id, \n",
    "  model=\"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "ftjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished once fine_tuned_model is not None\n",
    "\n",
    "client.fine_tuning.jobs.list(limit=10).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most recent job\n",
    "ftjob = client.fine_tuning.jobs.list(limit=10).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "training_results = pd.read_csv(BytesIO(client.files.content(ftjob.result_files[0]).content))[['step', 'train_loss', 'train_accuracy']]\n",
    "training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results['train_loss'].plot()\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results['train_accuracy'].plot()\n",
    "plt.title('Accuracy Plot')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(chat, dataset, truth_column='EDAM Topics', iterations=10, seed=54):\n",
    "    cost, accuracies = 0, []\n",
    "    io_pairs = []\n",
    "\n",
    "    random_samples = dataset.sample(n=iterations, random_state=seed)\n",
    "    \n",
    "    for idx, random_sample in tqdm(random_samples.iterrows(), total=random_samples.shape[0]):\n",
    "\n",
    "        _, abstract, paper_edam_topics = random_sample.loc[['Description', 'Abstract', truth_column]]\n",
    "\n",
    "        prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=f\"Generate a comma-separated list of relevant EDAM topics based on the provided abstract and topic categories.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "\n",
    "        gpt_output = ''\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            chat.invoke(messages)\n",
    "            for chunk in chat.stream(messages):\n",
    "                if type(chat) == ChatOpenAI:\n",
    "                    gpt_output += chunk.content\n",
    "                elif type(chat) == OpenAI:\n",
    "                    gpt_output += chunk\n",
    "            \n",
    "            cost += float(str(cb).split('$')[1])\n",
    "\n",
    "        try:\n",
    "            true_topics = dataset.loc[idx][truth_column]\n",
    "\n",
    "            accuracies.append(get_accuracy(gpt_output, true_topics))\n",
    "        except:\n",
    "            print('Error encountered at index', idx)\n",
    "\n",
    "        io_pairs.append([abstract, ', '.join(true_topics), gpt_output])\n",
    "\n",
    "    print('Average Accuracy:', np.mean(accuracies))\n",
    "    print('Total Cost ($):', cost)\n",
    "\n",
    "    return accuracies, cost, io_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(generated_topics, true_topics):\n",
    "    num_correct = 0\n",
    "\n",
    "    for topic in generated_topics.strip().split(', '):\n",
    "        if topic in true_topics:\n",
    "            num_correct += 1\n",
    "    \n",
    "    return num_correct / len(true_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = dataset.drop(training_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Model', 'Abstract', 'Ground Truth', 'Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01e312285d47ad9ca320ff2cfba4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.43995604395604393\n",
      "Total Cost ($): 0.0\n"
     ]
    }
   ],
   "source": [
    "# 100 training samples (11/06 version)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='ft:gpt-3.5-turbo-1106:personal::8SDAGTmv',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619e20a15170414fa47cdf622e2f1898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.47418681318681316\n",
      "Total Cost ($): 0.4389599999999999\n"
     ]
    }
   ],
   "source": [
    "# 100 training samples (06/13 version)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='ft:gpt-3.5-turbo-0613:personal::8SD8i1on',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad95142dab3430f811d6da2236f963b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.44755433455433463\n",
      "Total Cost ($): 0.438848\n"
     ]
    }
   ],
   "source": [
    "# 50 training samples (06/13 version)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='ft:gpt-3.5-turbo-0613:personal::8SAHvdnS',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cd8c04befb4a94ba8241a1517f273b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.09225457875457875\n",
      "Total Cost ($): 0.05483000000000001\n"
     ]
    }
   ],
   "source": [
    "# Non-fine tuned version. Default dated model\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d852bb20b0a4a5db48174432bb0b55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error encountered at index 469\n",
      "Error encountered at index 863\n",
      "Error encountered at index 47\n",
      "Error encountered at index 788\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/2s/m_y5ncrj7wv6_6bqg4l26hq00000gn/T/ipykernel_34281/3228132268.py\", line 8, in <module>\n",
      "    accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
      "  File \"/var/folders/2s/m_y5ncrj7wv6_6bqg4l26hq00000gn/T/ipykernel_34281/1021624183.py\", line 21, in test\n",
      "    chat.invoke(messages)\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/base.py\", line 142, in invoke\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/base.py\", line 459, in generate_prompt\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/base.py\", line 349, in generate\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/base.py\", line 339, in generate\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/base.py\", line 492, in _generate_with_cache\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/openai.py\", line 422, in _generate\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/langchain/chat_models/openai.py\", line 344, in completion_with_retry\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 303, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 598, in create\n",
      "    return self._post(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 1088, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 853, in request\n",
      "    return self._request(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 916, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 958, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 916, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 958, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/openai/_base_client.py\", line 930, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-zE0F8b8loFkufYbWEHjZdk2Q on tokens_usage_based per min: Limit 10000, Used 8668, Requested 1732. Please try again in 2.4s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens_usage_based', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/zubairqazi/miniconda3/envs/nde_gpt/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# Non fine-tuned GPT 4\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Ground Truth</th>\n",
       "      <th>Prioritized Predictions</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ft:gpt-3.5-turbo-1106:personal::8SDAGTmv</td>\n",
       "      <td>While microarray experiments generate volumino...</td>\n",
       "      <td>Animal study, Biology, Computational biology, ...</td>\n",
       "      <td>Animal study, Gene expression, Gene regulation...</td>\n",
       "      <td>Animal study, Gene expression, Gene regulation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ft:gpt-3.5-turbo-1106:personal::8SDAGTmv</td>\n",
       "      <td>Pea powdery mildew (PM) is an important fungal...</td>\n",
       "      <td>Computer science, Gene expression, Gene regula...</td>\n",
       "      <td>Agricultural science, DNA, Gene expression, Ge...</td>\n",
       "      <td>Agricultural science, Bioengineering, Bioinfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ft:gpt-3.5-turbo-1106:personal::8SDAGTmv</td>\n",
       "      <td>Differentiation proceeds along a continuum of ...</td>\n",
       "      <td>Animal study, Cardiology, DNA, Electrocardiogr...</td>\n",
       "      <td>Animal study, Cell culture collection, Chemist...</td>\n",
       "      <td>Animal study, Cell biology, Chemistry, Develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ft:gpt-3.5-turbo-1106:personal::8SDAGTmv</td>\n",
       "      <td>The annual migration of a bird can involve tho...</td>\n",
       "      <td>Animal study, Gene expression, Laboratory anim...</td>\n",
       "      <td>Animal study, Gene expression, Gene regulation...</td>\n",
       "      <td>Animal study, Gene expression, Laboratory anim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ft:gpt-3.5-turbo-1106:personal::8SDAGTmv</td>\n",
       "      <td>The utilization of methane, a potent greenhous...</td>\n",
       "      <td>Carbohydrates, Carbon cycle, Gene expression, ...</td>\n",
       "      <td>Carbon cycle, Chemistry, DNA replication and r...</td>\n",
       "      <td>Carbon cycle, Chemistry, Gene expression, Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Diagnostic and prognostic evaluation of chroni...</td>\n",
       "      <td>Antimicrobial Resistance, Gene expression, Gen...</td>\n",
       "      <td>Biomarkers, Biomedical science, Cell biology, ...</td>\n",
       "      <td>\"Immunology, Genetics, Genomics, Biomarkers, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>CTCF is a key insulator-binding protein, and m...</td>\n",
       "      <td>DNA binding sites, Mobile genetic elements, Pr...</td>\n",
       "      <td>DNA binding sites, Genomics, Molecular biology...</td>\n",
       "      <td>DNA binding sites, Genetics, Genomics, Molecul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Adipocytes arise from the commitment and diffe...</td>\n",
       "      <td>Animal study, Biomarkers, Laboratory animal sc...</td>\n",
       "      <td>Cell biology, Genetics, Molecular biology, Bio...</td>\n",
       "      <td>Bioinformatics, Cell biology, Genetics, Genomi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Tumor suppressive microRNA (miR)-150 inhibits ...</td>\n",
       "      <td>Animal study, Cell biology, Gene expression, G...</td>\n",
       "      <td>Bioinformatics, Cancer research, Cell biology,...</td>\n",
       "      <td>Cancer, Genetics, Genomics, Biochemistry, Cell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Bacterial genes that change in expression upon...</td>\n",
       "      <td>Cell culture collection, Gene expression, Gene...</td>\n",
       "      <td>Bioinformatics, Computational biology, Genetic...</td>\n",
       "      <td>Bioinformatics, Genetics, Genomics, Molecular ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model  \\\n",
       "0   ft:gpt-3.5-turbo-1106:personal::8SDAGTmv   \n",
       "1   ft:gpt-3.5-turbo-1106:personal::8SDAGTmv   \n",
       "2   ft:gpt-3.5-turbo-1106:personal::8SDAGTmv   \n",
       "3   ft:gpt-3.5-turbo-1106:personal::8SDAGTmv   \n",
       "4   ft:gpt-3.5-turbo-1106:personal::8SDAGTmv   \n",
       "..                                       ...   \n",
       "95                             gpt-3.5-turbo   \n",
       "96                             gpt-3.5-turbo   \n",
       "97                             gpt-3.5-turbo   \n",
       "98                             gpt-3.5-turbo   \n",
       "99                             gpt-3.5-turbo   \n",
       "\n",
       "                                             Abstract  \\\n",
       "0   While microarray experiments generate volumino...   \n",
       "1   Pea powdery mildew (PM) is an important fungal...   \n",
       "2   Differentiation proceeds along a continuum of ...   \n",
       "3   The annual migration of a bird can involve tho...   \n",
       "4   The utilization of methane, a potent greenhous...   \n",
       "..                                                ...   \n",
       "95  Diagnostic and prognostic evaluation of chroni...   \n",
       "96  CTCF is a key insulator-binding protein, and m...   \n",
       "97  Adipocytes arise from the commitment and diffe...   \n",
       "98  Tumor suppressive microRNA (miR)-150 inhibits ...   \n",
       "99  Bacterial genes that change in expression upon...   \n",
       "\n",
       "                                         Ground Truth  \\\n",
       "0   Animal study, Biology, Computational biology, ...   \n",
       "1   Computer science, Gene expression, Gene regula...   \n",
       "2   Animal study, Cardiology, DNA, Electrocardiogr...   \n",
       "3   Animal study, Gene expression, Laboratory anim...   \n",
       "4   Carbohydrates, Carbon cycle, Gene expression, ...   \n",
       "..                                                ...   \n",
       "95  Antimicrobial Resistance, Gene expression, Gen...   \n",
       "96  DNA binding sites, Mobile genetic elements, Pr...   \n",
       "97  Animal study, Biomarkers, Laboratory animal sc...   \n",
       "98  Animal study, Cell biology, Gene expression, G...   \n",
       "99  Cell culture collection, Gene expression, Gene...   \n",
       "\n",
       "                              Prioritized Predictions  \\\n",
       "0   Animal study, Gene expression, Gene regulation...   \n",
       "1   Agricultural science, DNA, Gene expression, Ge...   \n",
       "2   Animal study, Cell culture collection, Chemist...   \n",
       "3   Animal study, Gene expression, Gene regulation...   \n",
       "4   Carbon cycle, Chemistry, DNA replication and r...   \n",
       "..                                                ...   \n",
       "95  Biomarkers, Biomedical science, Cell biology, ...   \n",
       "96  DNA binding sites, Genomics, Molecular biology...   \n",
       "97  Cell biology, Genetics, Molecular biology, Bio...   \n",
       "98  Bioinformatics, Cancer research, Cell biology,...   \n",
       "99  Bioinformatics, Computational biology, Genetic...   \n",
       "\n",
       "                                          Predictions  \n",
       "0   Animal study, Gene expression, Gene regulation...  \n",
       "1   Agricultural science, Bioengineering, Bioinfor...  \n",
       "2   Animal study, Cell biology, Chemistry, Develop...  \n",
       "3   Animal study, Gene expression, Laboratory anim...  \n",
       "4   Carbon cycle, Chemistry, Gene expression, Gene...  \n",
       "..                                                ...  \n",
       "95  \"Immunology, Genetics, Genomics, Biomarkers, C...  \n",
       "96  DNA binding sites, Genetics, Genomics, Molecul...  \n",
       "97  Bioinformatics, Cell biology, Genetics, Genomi...  \n",
       "98  Cancer, Genetics, Genomics, Biochemistry, Cell...  \n",
       "99  Bioinformatics, Genetics, Genomics, Molecular ...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results.to_csv('outputs.csv', index=False)\n",
    "\n",
    "# Update old CSV\n",
    "old_results = pd.read_csv('outputs.csv')\n",
    "old_results.rename(columns={'Predictions': 'Prioritized Predictions'}, inplace=True)\n",
    "old_results['Predictions'] = results['Predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results.to_csv(\"outputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dynamically(string, max_line_length=80):\n",
    "    words = string.split()\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "\n",
    "    for word in words:\n",
    "        if len(current_line) + len(word) + 1 <= max_line_length:\n",
    "            current_line += word + \" \"\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = word + \" \"\n",
    "\n",
    "    lines.append(current_line)\n",
    "\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influenza A virus (IAV) and Streptococcus pyogenes (the group A Streptococcus; \n",
      "GAS) are important contributors to viral-bacterial superinfections, which \n",
      "result from incompletely defined mechanisms. We identified changes in gene \n",
      "expression following IAV infection of A549 cells. Changes included an increase \n",
      "in transcripts encoding proteins with fibronectin-type III (FnIII) domains, \n",
      "such as fibronectin (Fn), tenascin N (TNN), and tenascin C (TNC). We tested the \n",
      "idea that increased expression of TNC may affect the outcome of an IAV-GAS \n",
      "superinfection. To do so, we created a GAS strain that lacked the Fn-binding \n",
      "protein PrtF.2. We found that the wild-type GAS strain, but not the mutant, \n",
      "co-localized with TNC and bound to purified TNC. In addition, adherence of the \n",
      "wild-type strain to IAV-infected A549 cells was greater compared to the prtF.2 \n",
      "mutant. The wild-type strain was also more abundant in the lungs of mice 24 \n",
      "hours after superinfection compared to the mutant strain. Finally, all mice \n",
      "infected with IAV and the prtF.2 mutant strain survived superinfection compared \n",
      "to only 42% infected with IAV and the parental GAS strain, indicating that \n",
      "PrtF.2 contributes to virulence in a murine model of IAV-GAS superinfection. \n",
      "\n",
      "Model: ft:gpt-3.5-turbo-1106:personal::8SDAGTmv\n",
      "\n",
      "Ground Truth EDAM Topics:\n",
      "['Epigenetics', 'Human biology', 'Human genetics', 'Protein interactions', 'Sequence analysis']\n",
      "\n",
      "GPT Predicted EDAM Topics:\n",
      "Animal study, Gene expression, Genetic variation, Infectious disease, Laboratory animal science, Proteins, Virology\n"
     ]
    }
   ],
   "source": [
    "model, abstract, ground_truth, pred = results.sample(n=1).values[0]\n",
    "\n",
    "print_dynamically(abstract)\n",
    "\n",
    "print('\\nModel:', model)\n",
    "\n",
    "print('\\nGround Truth EDAM Topics:')\n",
    "print(ground_truth)\n",
    "\n",
    "print('\\nGPT Predicted EDAM Topics:')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
