{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT for Topic Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "\n",
    "import openai\n",
    "from langchain.llms import OpenAI \n",
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "EDAM topics, prompt, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = config[\"api_keys\"][\"openai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(input(\"Enter testing dataset path: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/prompt_template.txt', 'r') as template_file:\n",
    "    template = template_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input(\"Enter EDAM topics file:\"), 'r') as edam_file:\n",
    "    full_edam_topics = edam_file.readlines()\n",
    "\n",
    "full_edam_topics = [topic.strip() for topic in full_edam_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add EDAM topics to prompt template\n",
    "\n",
    "formatted_topics = \"\\n\".join(full_edam_topics)\n",
    "template = template.replace(\"<topics>\", formatted_topics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Remove non-unique terms from each row's EDAM topic list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(dataset['EDAM Topics'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "plt.hist(dataset['MeSH Terms'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Topics / Terms')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend(['EDAM', 'MeSH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total MeSH Terms:\", len(list(dataset.iloc[0]['MeSH Terms'])))\n",
    "print(\"Unique MeSH Terms:\", len(np.unique(list(dataset.iloc[0]['MeSH Terms']))))\n",
    "print()\n",
    "print(\"Total EDAM Topics:\", len(list(dataset.iloc[0]['EDAM Topics'])))\n",
    "print(\"Unique EDAM Topics:\", len(np.unique(list(dataset.iloc[0]['EDAM Topics']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['MeSH Terms'] = dataset['MeSH Terms'].apply(lambda mesh_list: np.unique(ast.literal_eval((mesh_list))))\n",
    "dataset['EDAM Topics'] = dataset['EDAM Topics'].apply(lambda edam_list: np.unique(ast.literal_eval((edam_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(dataset['EDAM Topics'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "plt.hist(dataset['MeSH Terms'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Topics / Terms')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend(['EDAM', 'MeSH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove any topics not in the EDAM Topics list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Filtered EDAM'] = dataset['EDAM Topics'].apply(lambda x: [item for item in x if item in full_edam_topics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(dataset['EDAM Topics'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "plt.hist(dataset['Filtered EDAM'].apply(len), bins='auto', edgecolor='black', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Number of Topics / Terms')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.legend(['EDAM', 'Filtered EDAM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any issues during filtering (missed topics, etc)\n",
    "\n",
    "indices_true = dataset.loc[dataset['Filtered EDAM'].apply(lambda edam_list: not all(term in full_edam_topics for term in edam_list))].index\n",
    "\n",
    "for index in indices_true:\n",
    "    edam_list = dataset.loc[index, 'Filtered EDAM']\n",
    "    terms_not_in_edam_topics = [term for term in edam_list if term not in full_edam_topics]\n",
    "    \n",
    "    print(f\"Index {index}: Terms not in edam_topics: {terms_not_in_edam_topics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API\n",
    "\n",
    "Let's start with a proof of concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = dataset.sample(n=1)\n",
    "\n",
    "index = random_sample.index[0]\n",
    "description, abstract, paper_edam_topics = random_sample[['Description', 'Abstract', 'Filtered EDAM']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "# prompt = template.replace('<description>', description).replace('<num_terms>', str(len(paper_edam_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=f\"You're a helpful assistant.\"),\n",
    "    HumanMessage(content=prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "gpt_output = ''\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chat.invoke(messages)\n",
    "    for chunk in chat.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        gpt_output += chunk.content\n",
    "    print(\"\\n===========CALLBACK: ==========\\n\")\n",
    "    print(cb)\n",
    "    print(\"\\n=============\\n\")\n",
    "\n",
    "\n",
    "# chat = OpenAI(\n",
    "#     model_name='text-davinci-003',\n",
    "#     openai_api_key = openai_api_key,\n",
    "#     temperature=0.75\n",
    "# )\n",
    "\n",
    "# gpt_output = ''\n",
    "\n",
    "# with get_openai_callback() as cb:\n",
    "#     chat.invoke(messages)\n",
    "#     for chunk in chat.stream(messages):\n",
    "#         print(chunk, end=\"\", flush=True)\n",
    "#         gpt_output += chunk\n",
    "#     print(\"\\n===========CALLBACK: ==========\\n\")\n",
    "#     print(cb)\n",
    "#     print(\"\\n=============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_edam = 0\n",
    "\n",
    "true_topics = dataset.iloc[index]['Filtered EDAM']\n",
    "num_correct = 0\n",
    "\n",
    "for topic in gpt_output.strip().split(', '):\n",
    "    if topic not in full_edam_topics:\n",
    "        print(topic)\n",
    "        not_in_edam += 1\n",
    "        continue\n",
    "\n",
    "    if topic in true_topics:\n",
    "        num_correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPT-outputted topics not in EDAM:\", not_in_edam)\n",
    "print(\"# Correct topics from GPT:\", num_correct)\n",
    "print(\"# Incorrect topics from GPT:\", len(true_topics) - num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpt_output, '\\n')\n",
    "print(', '.join(true_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: It seems as though GPT is not able to capture relevant topics given the entire list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPT to capture major subtopics (Biology, Medicine, etc.)\n",
    "\n",
    "We will see if GPT can capture the general topics of each data entry. Then we can pass the relevant subtopics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bioportal.bioontology.org/ontologies/EDAM/?p=classes&conceptid=http%3A%2F%2Fedamontology.org%2Ftopic_0003\n",
    "\n",
    "Biosciences - 4019\n",
    "\n",
    "Chemistry - 3314\n",
    "\n",
    "Computer science - 3316\n",
    "\n",
    "Data management - 3071\n",
    "\n",
    "Environmental Sciences - 3855\n",
    "\n",
    "Informatics - 0605\n",
    "\n",
    "Open science - 4010\n",
    "\n",
    "Physics - 3318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "edam_data = pd.read_csv(\"EDAM/EDAM.csv\")\n",
    "\n",
    "edam_data = edam_data[edam_data['Parents'].str.contains(\"http://edamontology.org/topic_\")]\n",
    "edam_data['Parents #'] = edam_data['Parents'].str.extractall(r'topic_(\\d+)').groupby(level=0).agg(lambda parents: parents.tolist())\n",
    "edam_data['Topic #'] = edam_data['Class ID'].apply(lambda url: url.split('topic_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "topics = ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318', '3361', '3068', '3678', '3315']\n",
    "\n",
    "subtopics = defaultdict(lambda: [])\n",
    "\n",
    "def get_children_topics(parent_id):\n",
    "    # children_ids = edam_data[edam_data['Parents'].str.contains(parent_id)]['Class ID'].apply(lambda url: url.split('topic_')[1]).to_list()\n",
    "    children_ids = edam_data[edam_data['Parents #'].apply(\\\n",
    "        lambda parent_ids: parent_id in parent_ids)]['Topic #'].to_list()\n",
    "    \n",
    "    if not len(children_ids):\n",
    "        return []\n",
    "    \n",
    "    # print(parent_id, children_ids)\n",
    "    \n",
    "    grandchildren = []\n",
    "    for child_id in children_ids:\n",
    "        grandchildren.append(get_children_topics(child_id))\n",
    "    \n",
    "    children_ids.append(grandchildren)\n",
    "    return children_ids\n",
    "\n",
    "for parent_topic in topics:\n",
    "    subtopics[parent_topic] = get_children_topics(parent_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    flattened = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened\n",
    "\n",
    "# Flatten each value in the dictionary\n",
    "subtopics = {key: flatten_list(value) for key, value in subtopics.items()}\n",
    "\n",
    "print()\n",
    "for key, value in subtopics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_to_remove = ['3361', '3068', '3678', '3315']\n",
    "topics_to_keep = ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318']\n",
    "\n",
    "for key in ['3361', '3068', '3678', '3315']:\n",
    "    topics_to_remove.extend(subtopics[key])\n",
    "\n",
    "for key in ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318']:\n",
    "    topics_to_keep.extend(subtopics[key])\n",
    "\n",
    "topics_to_remove, topics_to_keep = set(topics_to_remove), set(topics_to_keep)\n",
    "\n",
    "print('Number of Topics to remove: ', len([item for item in topics_to_remove if item not in topics_to_keep]))\n",
    "\n",
    "edam_data = edam_data[~edam_data['Topic #'].apply(lambda topic: topic in topics_to_remove and topic not in topics_to_keep)]\n",
    "\n",
    "# Remove the unnecessary topics =\n",
    "for topic in ['3361', '3068', '3678', '3315']:\n",
    "    del subtopics[topic]\n",
    "\n",
    "print()\n",
    "for key, value in subtopics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_topics = defaultdict(lambda: set())\n",
    "\n",
    "for key, values in subtopics.items():\n",
    "    for value in values:\n",
    "        parent_topics[value].add(key)\n",
    "\n",
    "\n",
    "for key, value in parent_topics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topics = {}\n",
    "\n",
    "for topic in ['4019', '3314', '3316', '3071', '3855', '0605', '4010', '3318']:\n",
    "    main_topics[topic] = edam_data[edam_data['Topic #'] == topic]['Preferred Label'].values[0]\n",
    "\n",
    "main_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edam_data['Parent Topics'] = edam_data['Topic #'].apply(lambda topic:[main_topics[parent_topic] for parent_topic in parent_topics[topic]])\n",
    "edam_data['Parent Topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Topic Category'] = dataset['Filtered EDAM'].apply(lambda edam_list: [edam_data[edam_data['Preferred Label'] == topic]['Parent Topics'].values[0] for topic in edam_list])\\\n",
    "    .apply(lambda parent_list: set([item for sublist in parent_list for item in sublist]))\n",
    "\n",
    "dataset['Topic Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT for topic categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('templates/prompt_template.txt', 'r') as template_file:\n",
    "    template = template_file.read()\n",
    "\n",
    "formatted_topics = \"\\n\".join(main_topics.values())\n",
    "template = template.replace(\"<topics>\", formatted_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(generated_topics, true_topics):\n",
    "    num_correct = 0\n",
    "\n",
    "    for topic in generated_topics.strip().split(', '):\n",
    "        if topic in true_topics:\n",
    "            num_correct += 1\n",
    "    \n",
    "    return num_correct / len(true_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(chat, dataset, truth_column='Topic Category', iterations=10):\n",
    "    cost, accuracies = 0, []\n",
    "    io_pairs = []\n",
    "    \n",
    "    for _ in tqdm(range(iterations)): \n",
    "        random_sample = dataset.sample(n=1)\n",
    "\n",
    "        index = random_sample.index[0]\n",
    "        _, abstract, paper_edam_topics = random_sample[['Description', 'Abstract', truth_column]].values[0]\n",
    "\n",
    "        prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=f\"Generate a comma-separated list of relevant EDAM topics based on the provided abstract and topic categories.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "\n",
    "        gpt_output = ''\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            chat.invoke(messages)\n",
    "            for chunk in chat.stream(messages):\n",
    "                if type(chat) == ChatOpenAI:\n",
    "                    gpt_output += chunk.content\n",
    "                elif type(chat) == OpenAI:\n",
    "                    gpt_output += chunk\n",
    "            \n",
    "            cost += float(str(cb).split('$')[1])\n",
    "\n",
    "        try:\n",
    "            true_topics = dataset.iloc[index][truth_column]\n",
    "\n",
    "            accuracies.append(get_accuracy(gpt_output, true_topics))\n",
    "        except:\n",
    "            print('Error encountered at index', index)\n",
    "\n",
    "        io_pairs.append([abstract, ', '.join(true_topics), gpt_output])\n",
    "\n",
    "    print('Average Accuracy:', np.mean(accuracies))\n",
    "    print('Total Cost ($):', cost)\n",
    "\n",
    "    return accuracies, cost, io_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, _ = test(chat, dataset, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = OpenAI(\n",
    "    model_name='text-davinci-003',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, _ = test(chat, dataset, iterations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, _ = test(chat, dataset, iterations=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double num_topics \n",
    "\n",
    "Attempting to see if GPT will eventually get the correct topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = dataset.sample(n=1)\n",
    "\n",
    "index = random_sample.index[0]\n",
    "description, abstract, paper_edam_topics = random_sample[['Description', 'Abstract', 'Filtered EDAM']].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics) * 2))\n",
    "# prompt = template.replace('<description>', description).replace('<num_terms>', str(len(paper_edam_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=f\"You're a helpful assistant.\"),\n",
    "    HumanMessage(content=prompt)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "gpt_output = ''\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    chat.invoke(messages)\n",
    "    for chunk in chat.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "        gpt_output += chunk.content\n",
    "    print(\"\\n===========CALLBACK: ==========\\n\")\n",
    "    print(cb)\n",
    "    print(\"\\n=============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(gpt_output, paper_edam_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abstract, '\\n')\n",
    "print(gpt_output)\n",
    "print(', '.join(random_sample['Filtered EDAM'].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some potential, but requires further exploration. The main question to focus on is the definition of success, and how to measure whether the predicted topics are valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with 50 training samples for fine-tuning. (https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "training_data = dataset.sample(n=n, replace=False, random_state=50)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"datasets/finetune-data-{n}.jsonl\", 'w') as file:\n",
    "    for idx, row in training_data.iterrows():\n",
    "        description, abstract, paper_edam_topics = row[['Description', 'Abstract', 'Filtered EDAM']]\n",
    "        prompt = template.replace('<abstract>', abstract).replace('<num_terms>', str(len(paper_edam_topics)))\n",
    "\n",
    "        json_data = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Generate a comma-separated list of relevant EDAM topics based on the provided abstract and topic categories.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "                {\"role\": \"assistant\", \"content\": ', '.join(paper_edam_topics)}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        file.write(json.dumps(json_data))\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```Chat_finetuning_data_prep.ipynb``` to check for any errors in the data and to get the cost estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "fileobj = client.files.create(\n",
    "  file=open(f\"datasets/finetune-data-{n}.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "fileobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftjob = client.fine_tuning.jobs.create(\n",
    "  training_file=fileobj.id, \n",
    "  model=\"gpt-3.5-turbo-1106\"\n",
    ")\n",
    "\n",
    "ftjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finished once fine_tuned_model is not None\n",
    "\n",
    "client.fine_tuning.jobs.list(limit=10).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most recent job\n",
    "ftjob = client.fine_tuning.jobs.list(limit=10).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "training_results = pd.read_csv(BytesIO(client.files.content(ftjob.result_files[0]).content))[['step', 'train_loss', 'train_accuracy']]\n",
    "training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results['train_loss'].plot()\n",
    "plt.title('Loss Plot')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_results['train_accuracy'].plot()\n",
    "plt.title('Accuracy Plot')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = dataset.drop(training_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Model', 'Abstract', 'Ground Truth', 'Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 training samples (11/06 version)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='ft:gpt-3.5-turbo-1106:personal::8SDAGTmv',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 training samples (06/13 version)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='ft:gpt-3.5-turbo-0613:personal::8SD8i1on',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 training samples (06/13 version)\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='ft:gpt-3.5-turbo-0613:personal::8SAHvdnS',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-fine tuned version. Default dated model\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non fine-tuned GPT 4\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4',\n",
    "    openai_api_key = openai_api_key\n",
    ")\n",
    "\n",
    "accuracies, cost, io_pairs = test(chat, testing_data, truth_column='Filtered EDAM', iterations=25)\n",
    "\n",
    "for abstract, ground_truth, predictions in io_pairs:\n",
    "    row = {'Model': chat.model_name, 'Abstract': abstract, 'Ground Truth': ground_truth, 'Predictions': predictions}\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dynamically(string, max_line_length=80):\n",
    "    words = string.split()\n",
    "    lines = []\n",
    "    current_line = \"\"\n",
    "\n",
    "    for word in words:\n",
    "        if len(current_line) + len(word) + 1 <= max_line_length:\n",
    "            current_line += word + \" \"\n",
    "        else:\n",
    "            lines.append(current_line)\n",
    "            current_line = word + \" \"\n",
    "\n",
    "    lines.append(current_line)\n",
    "\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influenza A virus (IAV) and Streptococcus pyogenes (the group A Streptococcus; \n",
      "GAS) are important contributors to viral-bacterial superinfections, which \n",
      "result from incompletely defined mechanisms. We identified changes in gene \n",
      "expression following IAV infection of A549 cells. Changes included an increase \n",
      "in transcripts encoding proteins with fibronectin-type III (FnIII) domains, \n",
      "such as fibronectin (Fn), tenascin N (TNN), and tenascin C (TNC). We tested the \n",
      "idea that increased expression of TNC may affect the outcome of an IAV-GAS \n",
      "superinfection. To do so, we created a GAS strain that lacked the Fn-binding \n",
      "protein PrtF.2. We found that the wild-type GAS strain, but not the mutant, \n",
      "co-localized with TNC and bound to purified TNC. In addition, adherence of the \n",
      "wild-type strain to IAV-infected A549 cells was greater compared to the prtF.2 \n",
      "mutant. The wild-type strain was also more abundant in the lungs of mice 24 \n",
      "hours after superinfection compared to the mutant strain. Finally, all mice \n",
      "infected with IAV and the prtF.2 mutant strain survived superinfection compared \n",
      "to only 42% infected with IAV and the parental GAS strain, indicating that \n",
      "PrtF.2 contributes to virulence in a murine model of IAV-GAS superinfection. \n",
      "\n",
      "Model: ft:gpt-3.5-turbo-1106:personal::8SDAGTmv\n",
      "\n",
      "Ground Truth EDAM Topics:\n",
      "['Epigenetics', 'Human biology', 'Human genetics', 'Protein interactions', 'Sequence analysis']\n",
      "\n",
      "GPT Predicted EDAM Topics:\n",
      "Animal study, Gene expression, Genetic variation, Infectious disease, Laboratory animal science, Proteins, Virology\n"
     ]
    }
   ],
   "source": [
    "model, abstract, ground_truth, pred = results.sample(n=1).values[0]\n",
    "\n",
    "print_dynamically(abstract)\n",
    "\n",
    "print('\\nModel:', model)\n",
    "\n",
    "print('\\nGround Truth EDAM Topics:')\n",
    "print(ground_truth)\n",
    "\n",
    "print('\\nGPT Predicted EDAM Topics:')\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
